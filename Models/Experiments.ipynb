{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"pip install --upgrade pip","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install jsonlines","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install transformers\n#!wget -O scibert_uncased.tar https://s3-us-west-2.amazonaws.com/ai2-s2-research/scibert/huggingface_pytorch/scibert_scivocab_uncased.tar\n#!tar -xvf scibert_uncased.tar\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport jsonlines\nimport os\nimport re\nimport torch\nimport math\nimport random\nfrom sklearn.metrics import f1_score\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom transformers import AutoTokenizer, AutoModel\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom collections import Counter\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nfrom IPython.display import FileLink,FileLinks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scicite data loading............\ntrain_main = '../input/dataset/scicite/train.jsonl'\ntest_main = '../input/dataset/scicite/test.jsonl'\nval_main = '../input/dataset/scicite/dev.jsonl'\nsec_sc = '../input/dataset/scicite/scaffolds/sections-scaffold-train.jsonl'\ncit_sc = '../input/dataset/scicite/scaffolds/cite-worthiness-scaffold-train.jsonl'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ACL data loading............\nacl_train_main = '../input/acl-cohan-preprocessed-dataset/train.jsonl'\nacl_test_main = '../input/acl-cohan-preprocessed-dataset/test.jsonl'\nacl_val_main = '../input/acl-cohan-preprocessed-dataset/dev.jsonl'\nacl_sec_sc = '../input/acl-cohan-preprocessed-dataset/sections-scaffold-train.jsonl'\nacl_cit_sc = '../input/acl-cohan-preprocessed-dataset/cite-worthiness-scaffold-train.jsonl'\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **SECTION SCAFFOLD DATA REVIEW**"},{"metadata":{"trusted":true},"cell_type":"code","source":"p=[]\nwith jsonlines.open(sec_sc) as f:\n    for line in f.iter():\n        p.append(line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"line.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.DataFrame(p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['section_name'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[['citing_paper_id','cleaned_cite_text','section_title','citation_id','is_citation']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['section_name'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(data['is_citation']==False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()['cleaned_cite_text'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(data['text']==data['cleaned_cite_text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(data['section_name']==data['section_title'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **CITATION WORTHINESS SCAFFOLD DATA REVIEW**"},{"metadata":{"trusted":true},"cell_type":"code","source":"q=[]\nwith jsonlines.open(cit_sc) as f:\n    for line in f.iter():\n        q.append(line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"line.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datac = pd.DataFrame(q)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datac['is_citation'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datac[['text','citing_paper_id','cleaned_cite_text','citation_id','is_citation']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datac.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(datac['text']!=datac['cleaned_cite_text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d=datac.loc[datac['text']!=datac['cleaned_cite_text']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d['text'][5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d['cleaned_cite_text'][5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datac.head()['text'][4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datac.head()['cleaned_cite_text'][4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datac.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **MAIN TASK DATA REVIEW**"},{"metadata":{"trusted":true},"cell_type":"code","source":"tm=[]\nwith jsonlines.open(train_main) as f:\n    for line in f.iter():\n        tm.append(line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pdm = pd.DataFrame(tm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pdm['string'][6540]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pdm['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pdm.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"pdm.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **CITED PAPER TITLE SCAFFOLD**"},{"metadata":{"trusted":true},"cell_type":"code","source":"pdtr = pd.read_csv('../input/pride-data/train.csv')\npdte = pd.read_csv('../input/pride-data/test.csv')\npdtr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pdtr['citation_context'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_tit = pdtr['cited_title'].values.tolist()\nlen(x_tit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yc = pdtr['citation_class_label'].values.tolist()\nlabel={0:0,1:2,2:1,3:0,4:0,5:1}\ny_tit = list(map(lambda t : label[t],yc))\nlen(y_tit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\nx_tit = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=70),x_tit))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_tit = torch.tensor(y_tit)\nx_tit = torch.tensor(x_tit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_tit.shape)\nprint(y_tit.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **ACL DATA LOADING.....**"},{"metadata":{"trusted":true},"cell_type":"code","source":"p=[]\nwith jsonlines.open(acl_sec_sc) as f:\n    for line in f.iter():\n        p.append(line)\nacl_secdata = pd.DataFrame(p)\nacl_secdata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acl_secdata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q=[]\nwith jsonlines.open(acl_cit_sc) as f:\n    for line in f.iter():\n        q.append(line)\nacl_citdata = pd.DataFrame(q)\nacl_citdata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acl_citdata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tm=[]\nwith jsonlines.open(acl_train_main) as f:\n    for line in f.iter():\n        tm.append(line)\nacl_pdm = pd.DataFrame(tm)\nacl_pdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acl_pdm.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **DATA PREP**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_idx(l,max_len): # max_len = len of tokens criteria above which to remove\n    lent = []\n    idx_remove = []\n    for i in l:\n        lent.append(len(tokenizer.encode(i, padding=True, truncation=True, return_tensors=\"pt\")[0]))\n    for i in range(len(lent)):\n        if(lent[i]>max_len):\n            idx_remove.append(i)\n    return idx_remove","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# returns balanced dataset.....\ndef class_div(X,Y,instances,num_class):\n    inst_per_class = instances//num_class\n    rem = instances%num_class\n    x_out=[]\n    y_out=[]\n    for i in range(num_class):\n        xcl = [x for x,y in zip(X,Y) if y==i]\n        ycl = [y for y in Y if y==i]\n        print('xcl length : ',len(xcl))\n        if(rem):\n            x_out += xcl[:inst_per_class+1]\n            y_out += ycl[:inst_per_class+1]\n            rem -= 1\n            print('x_out length : ',len(x_out))\n        else:\n            x_out += xcl[:inst_per_class]\n            y_out += ycl[:inst_per_class]\n            print('x_out length : ',len(x_out))\n    return (x_out,y_out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef fun(i):\n    pat = ' '.join(re.split(r'\\[[^\\[\\]]*\\]' ,i))\n    pat = ' '.join(re.split(r'\\([^\\[\\]\\(\\)]*\\)' ,pat))\n    return pat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"citm=pdm['string'].values.tolist()\ncitm = [fun(i) for i in citm]\npdm['processed_text'] = citm\nlen(citm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yc = pdm['label'].values.tolist()\nlabel={'background':0,'method':1,'result':2}\ny = list(map(lambda t : label[t],yc))\nlen(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"citm_idx_remove_300 = remove_idx(citm,300)\nfor i in sorted(citm_idx_remove_300, reverse = True):  \n    del citm[i]\n    del y[i]\nprint(f'removed {len(citm_idx_remove_300)} instances')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_cit = datac['cleaned_cite_text'].values.tolist()\nx_cit = [fun(i) for i in x_cit]\ndatac['processed_text'] = x_cit\nlen(x_cit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ycit = datac['is_citation'].values.tolist()\nycit_ie = list(map(lambda x : int(x),ycit))\nlen(ycit_ie)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xcit_idx_remove_300 = remove_idx(x_cit,300)\nfor i in sorted(xcit_idx_remove_300, reverse = True):  \n    del x_cit[i]\n    del ycit_ie[i]\nprint(f'removed {len(xcit_idx_remove_300)} instances')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_sec = data['text'].values.tolist()\nx_sec = [fun(i) for i in x_sec]\ndata['processed_text'] = x_sec\nlen(x_sec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_sec = data['section_name'].values.tolist()\nlabels={'introduction':0,'related work':1,'method':2,'experiments':3,'conclusion':4}\nysec_ie = list(map(lambda t : labels[t],y_sec))\nlen(ysec_ie)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xsec_idx_remove_300 = remove_idx(x_sec,300)\nfor i in sorted(xsec_idx_remove_300, reverse = True):  \n    del x_sec[i]\n    del ysec_ie[i]\nprint(f'removed {len(xsec_idx_remove_300)} instances')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(x_sec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Method 2 = By balancing the data\nxsecc,ysecc = class_div(x_sec,ysec_ie,8228,5)\nprint('*'*40)\nxcitt,ycitt = class_div(x_cit,ycit_ie,8228,2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(ycitt).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for v-1 model = method - 1 = without balancing the data\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\nx = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=300),citm))\n\ny = torch.tensor(y[:-2])\nx = torch.tensor(x[:-2])\nprint('x.shape : ',x.shape)\nprint('y.shape : ',y.shape)\n\nxcit = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=300),x_cit))\n\nxsec = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=300),x_sec))\n\nsec = [(x,y) for x,y in zip(xsec,ysec_ie)]\nsec = random.sample(sec, 8232)\n\ncit = [(x,y) for x,y in zip(xcit,ycit_ie)]\ncit = random.sample(cit, 8232)\n\nxcit = torch.tensor([t[0] for t in cit])\nycit = torch.tensor([t[1] for t in cit])\nxsec = torch.tensor([t[0] for t in sec])\nysec = torch.tensor([t[1] for t in sec])\nprint(xcit.shape)\nprint(xsec.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#for v-1 model = method - 2 = after balancing the data\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\nx = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=300),citm))\n\ny = torch.tensor(y)\nx = torch.tensor(x)\nprint('x.shape : ',x.shape)\nprint('y.shape : ',y.shape)\n\nxcit = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=300),xcitt))\nxcit = torch.tensor(xcit)\nycit = torch.tensor(ycitt)\nprint('xcit shape : ',xcit.shape)\n\nxsec = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=300),xsecc))\nxsec = torch.tensor(xsec)\nysec = torch.tensor(ysecc)\nprint('xsec shape : ',xsec.shape)\nprint(ysec.shape)\nprint(ycit.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(ysec).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for v-2 model : including all 3 scaffolds\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\nx = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=70),citm))\n\nm = [(x,y) for x,y in zip(x,y)]\nm = random.sample(m, 3000)\n\nx = [i[0] for i in m]\ny = [i[1] for i in m]\n\ny = torch.tensor(y)\nx = torch.tensor(x)\nprint(x.shape)\nprint(y.shape)\n\nxcit = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=70),x_cit))\nxsec = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=70),x_sec))\n\nsec = [(x,y) for x,y in zip(xsec,ysec_ie)]\nsec = random.sample(sec, 3000)\n\ncit = [(x,y) for x,y in zip(xcit,ycit_ie)]\ncit = random.sample(cit, 3000)\n\nxcit = torch.tensor([t[0] for t in cit])\nycit = torch.tensor([t[1] for t in cit])\nxsec = torch.tensor([t[0] for t in sec])\nysec = torch.tensor([t[1] for t in sec])\nprint(xcit.shape)\nprint(xsec.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **ACL Data prep**"},{"metadata":{"trusted":true},"cell_type":"code","source":"acl_x_cit = acl_citdata['cleaned_cite_text'].values.tolist()\nlen(acl_x_cit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acl_ycit = acl_citdata['is_citation'].values.tolist()\nacl_ycit_ie = list(map(lambda x : int(x),acl_ycit))\nlen(acl_ycit_ie)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\nacl_xcit_idx_remove_300 = remove_idx(acl_x_cit,300)\nfor i in sorted(acl_xcit_idx_remove_300, reverse = True):  \n    del acl_x_cit[i]\n    del acl_ycit_ie[i]\nprint(f'removed {len(acl_xcit_idx_remove_300)} instances')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acl_x_sec = acl_secdata['text'].values.tolist()\nlen(acl_x_sec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acl_y_sec = acl_secdata['section_name'].values.tolist()\nlabels={'introduction':0,'related work':1,'method':2,'experiments':3,'conclusion':4}\nacl_ysec_ie = list(map(lambda t : labels[t],acl_y_sec))\nlen(acl_ysec_ie)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acl_xsec_idx_remove_300 = remove_idx(acl_x_sec,300)\nfor i in sorted(acl_xsec_idx_remove_300, reverse = True):  \n    del acl_x_sec[i]\n    del acl_ysec_ie[i]\nprint(f'removed {len(acl_xsec_idx_remove_300)} instances')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for v-1 model = method - 1 = without balancing the main data\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\nacl_tr = list(acl_pdm['cleaned_cite_text'])\nacl_y = acl_pdm['intent'].values.tolist()\nacl_label={'Background':0,'CompareOrContrast':1,'Extends':2,'Future':3,'Motivation':4,'Uses':5}\nacl_y = list(map(lambda t : acl_label[t],acl_y))\n\nprint(acl_y[:5])\n\nacl_tr_idx_remove_300 = remove_idx(acl_tr,300)\nfor i in sorted(acl_tr_idx_remove_300, reverse = True):  \n    del acl_tr[i]\n    del acl_y[i]\nprint(f'removed {len(acl_tr_idx_remove_300)} instances')\n\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\nacl_x = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=300),acl_tr))\nacl_y = torch.tensor(acl_y)\nacl_x = torch.tensor(acl_x)\nprint(acl_x[:5])\nprint(acl_x.shape)\nprint(acl_y[:5])\nprint(acl_y.shape)\n\n# By balancing the scaffold data only........\nxsecc,ysecc = class_div(acl_x_sec,acl_ysec_ie,1688,5)\nprint('*'*40)\nxcitt,ycitt = class_div(acl_x_cit,acl_ycit_ie,1688,2)\n\nxcit = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=300),xcitt))\n\nxsec = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=300),xsecc))\n\nxsec = torch.tensor(xsec)\nxcit = torch.tensor(xcit)\nycit = torch.tensor(ycitt)\nysec = torch.tensor(ysecc)\nprint(xcit.shape)\nprint(ycit.shape)\nprint(xsec.shape)\nprint(ysec.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# validation data\nvm=[]\nwith jsonlines.open(acl_val_main) as f:\n    for line in f.iter():\n        vm.append(line)\nacl_pdvm = pd.DataFrame(vm)\nacl_pdvm        \n\nacl_citvm=acl_pdvm['text'].values.tolist()\nacl_yc = acl_pdvm['intent'].values.tolist()\nlabel={'Background':0,'CompareOrContrast':1,'Extends':2,'Future':3,'Motivation':4,'Uses':5}\nacl_vy = list(map(lambda t : label[t],acl_yc))\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\nvx = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=300),acl_citvm))\nvy = torch.tensor(acl_vy[:-2])\nvx = torch.tensor(vx[:-2])\nprint(vx.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"acl_pdtm.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test data\ntestm=[]\nwith jsonlines.open(acl_test_main) as f:\n    for line in f.iter():\n        testm.append(line)\nacl_pdtm = pd.DataFrame(testm)\nacl_pdtm        \n\nacl_cittem=acl_pdtm[:-1]['text'].values.tolist()\nacl_yc = acl_pdtm[:-1]['intent'].values.tolist()\nlabel={'Background':0,'CompareOrContrast':1,'Extends':2,'Future':3,'Motivation':4,'Uses':5}\nty = list(map(lambda t : label[t],acl_yc))\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\ntx = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=300),acl_cittem))\nty = torch.tensor(ty[:-2])\ntx = torch.tensor(tx[:-2])\nprint(tx.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# check for torch.mm used in attention class (rough) #when w for att. weights shape = (2*hidden,1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"wl=torch.rand(10,1)\nwl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xl=torch.randn(3,10,10)\nn = torch.mm(xl.view(-1,10),wl)\nn.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xl[1][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n.view(-1,10,1)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"F.softmax(n.view(-1,10,1),dim=1)[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# custom softmax function for cross-checking\ns=0\nl=[]\nfor i in range(n.view(-1,10,1)[1].shape[0]):\n    t = n.view(-1,10,1)[1][i]\n    l.append(np.exp(t.item()))\n    s+=np.exp(t.item())\nl/s","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# check for torch.bmm used in attention class (rough) #when w in att. weights shape = (batch_size,2*hidden,1)"},{"metadata":{"trusted":true},"cell_type":"code","source":"x1=torch.rand(3,10,10)\nw1=torch.rand(3,10,1)\ne1=torch.bmm(x1,w1)\ne1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"e1[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# custom softmax to crosscheck the values \ns1=0\nl1=[]\nfor i in range(e1.shape[1]):\n    t = e1[1][i]\n    l1.append(np.exp(t.item()))\n    s1+=np.exp(t.item())\nl1/s1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"F.softmax(e1,dim=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **MODEL v-1**"},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class attention(nn.Module):\n    def __init__(self,batch_size,hidden_size=50,max_len=300):\n        super().__init__()\n        k = torch.empty(batch_size,2*hidden_size,1)\n        self.w = torch.nn.init.xavier_uniform_(k).to(device)\n        self.hidden = hidden_size\n        self.max_len = max_len\n    def forward(self,x):\n        #e = torch.mm(x.view(-1,2*hidden_size),self.w).view(-1,max_len,1)\n        # x.shape = (batch_size,max_len,2*hidden_size), w.shape = (2*hidden_size,1)\n        # e.shape = (batch_size,max_len,1)\n        # later on also try with w.shape = (batch_size,2*hidden,1) ; use torch.bmm(x,w) in that case instead of above np.dot implementation\n        e = torch.bmm(x,self.w)/math.sqrt(self.hidden)\n        att_weights = F.softmax(e,dim=1) # attention weights shape = (batch_size,max_len,1)\n        out = torch.bmm(x.transpose(1,2),att_weights)\n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feed forward of main task\nclass feedforward1(nn.Module):\n    def __init__(self,data):\n        super().__init__()\n        \n        n = 3 if data=='sci' else 6\n            \n        self.drop = nn.Dropout(p=0.2)\n        self.lin = nn.Linear(100,20)\n        self.relu = torch.nn.ReLU()\n        self.out = nn.Linear(20,n)\n    def forward(self,x):\n        x = self.drop(x)\n        lin_out = self.lin(x)\n        x = self.relu(lin_out)\n        x = self.out(x)\n        return (x,lin_out) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feed forward of section scaffold\nclass feedforward2(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.drop = nn.Dropout(p=0.2)\n        self.lin = nn.Linear(100,20)\n        self.relu = torch.nn.ReLU()\n        self.out = nn.Linear(20,5)\n    def forward(self,x):\n        x = self.drop(x)\n        lin_out = self.lin(x)\n        x = self.relu(lin_out)\n        x = self.out(x)\n        return (x,lin_out) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feed forward of citation worthiness scaffold\nclass feedforward3(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.drop = nn.Dropout(p=0.2)\n        self.lin = nn.Linear(100,20)\n        self.relu = torch.nn.ReLU()\n        self.out = nn.Linear(20,2)\n    def forward(self,x):\n        x = self.drop(x)\n        lin_out = self.lin(x)\n        x = self.relu(lin_out)\n        x = self.out(x)\n        return (x,lin_out) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class model(nn.Module):\n    def __init__(self,batch_size):\n        super().__init__()\n        self.batch_size = batch_size\n        self.BertModel = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n        self.lstm = nn.LSTM(768,50,num_layers=1,bidirectional=True,batch_first=True)\n        self.att = attention(batch_size)\n        self.main_sci = feedforward1(data='sci')\n        self.main_pk = feedforward1(data='pk')\n        self.sec = feedforward2()\n        self.cit = feedforward3()\n    def forward(self,x,n,data=None):\n        xbert=self.BertModel(x)\n        lstm,_=self.lstm(xbert[0])\n        att = self.att(lstm).view(self.batch_size,100)\n        if(n==1 and data=='sci'):\n            return self.main_sci(att)[0]\n        \n        elif(n==1 and data=='pk'):\n            return self.main_pk(att)[0]\n        \n        elif(n==2):\n            return self.sec(att)[0]\n        \n        elif(n==3):\n            return self.cit(att)[0]\n        else:\n            # predicting == training done!!\n            if(data=='sci'):\n                z,last = self.main_sci(att)\n                _,last_sec = self.sec(att)\n                _,last_cit = self.cit(att)\n            else:\n                z,last = self.main_pk(att)\n                _,last_sec = self.sec(att)\n                _,last_cit = self.cit(att)\n            z = F.softmax(z,dim=1)\n            z = torch.argmax(z,dim=1)\n            return (z,last,att,last_cit,last_sec)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"x = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=100),list(pdm['string'])))\nx = torch.tensor(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"luv = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")(x[0].view(1,-1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"luv[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lst = nn.LSTM(768,50,num_layers=1,bidirectional=True,batch_first=True)(luv[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lst[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"att = attention(1)(lst[0].cuda())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"att.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **MODEL v-2**"},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class attention(nn.Module):\n    def __init__(self,batch_size,hidden_size=50,max_len=70):\n        super().__init__()\n        k = torch.empty(batch_size,2*hidden_size,1)\n        self.w = torch.nn.init.xavier_uniform_(k).to(device)\n        self.hidden = hidden_size\n        self.max_len = max_len\n    def forward(self,x):\n        #e = torch.mm(x.view(-1,2*hidden_size),self.w).view(-1,max_len,1)\n        # x.shape = (batch_size,max_len,2*hidden_size), w.shape = (2*hidden_size,1)\n        # e.shape = (batch_size,max_len,1)\n        # later on also try with w.shape = (batch_size,2*hidden,1) ; use torch.bmm(x,w) in that case instead of above np.dot implementation\n        e = torch.bmm(x,self.w)/math.sqrt(self.hidden)\n        att_weights = F.softmax(e,dim=1) # attention weights shape = (batch_size,max_len,1)\n        out = torch.bmm(x.transpose(1,2),att_weights)\n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feed forward of main task\nclass feedforward1(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.drop = nn.Dropout(p=0.3)\n        self.lin = nn.Linear(100,20)\n        self.relu = torch.nn.ReLU()\n        self.out = nn.Linear(20,3)\n    def forward(self,x):\n        x = self.drop(x)\n        x = self.lin(x)\n        x = self.relu(x)\n        x = self.out(x)\n        return x ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feed forward of section scaffold\nclass feedforward2(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.drop = nn.Dropout(p=0.3)\n        self.lin = nn.Linear(100,20)\n        self.relu = torch.nn.ReLU()\n        self.out = nn.Linear(20,5)\n    def forward(self,x):\n        x = self.drop(x)\n        x = self.lin(x)\n        x = self.relu(x)\n        x = self.out(x)\n        return x ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feed forward of citation worthiness scaffold\nclass feedforward3(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.drop = nn.Dropout(p=0.3)\n        self.lin = nn.Linear(100,20)\n        self.relu = torch.nn.ReLU()\n        self.out = nn.Linear(20,2)\n    def forward(self,x):\n        x = self.drop(x)\n        x = self.lin(x)\n        x = self.relu(x)\n        x = self.out(x)\n        return x ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feed forward of cited paper title scaffold\nclass feedforward4(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.drop = nn.Dropout(p=0.3)\n        self.lin = nn.Linear(100,20)\n        self.relu = torch.nn.ReLU()\n        self.out = nn.Linear(20,3)\n    def forward(self,x):\n        x = self.drop(x)\n        x = self.lin(x)\n        x = self.relu(x)\n        x = self.out(x)\n        return x ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class modelv2(nn.Module):\n    def __init__(self,batch_size):\n        super().__init__()\n        self.batch_size = batch_size\n        self.BertModel = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n        self.lstm = nn.LSTM(768,50,num_layers=1,bidirectional=True,batch_first=True)\n        self.att = attention(batch_size)\n        self.main = feedforward1()\n        self.sec = feedforward2()\n        self.cit = feedforward3()\n        self.tit = feedforward4()\n        \n    def forward(self,x,n):\n        xbert=self.BertModel(x)\n        lstm,_=self.lstm(xbert[0])\n        z = self.att(lstm).view(self.batch_size,100)\n        if(n==1):\n            return self.main(z)\n        \n        elif(n==2):\n            return self.sec(z)\n        \n        elif(n==3):\n            return self.cit(z)\n        elif(n==4):\n            return self.tit(z)\n        else:\n            #predicting == training done!!\n            z = self.main(z)\n            z = F.softmax(z,dim=1)\n            return torch.argmax(z,dim=1)\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Model v-3**"},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k = torch.empty(1,4,1)\nhidden = 50\nprint(k)\nwe = torch.nn.init.xavier_uniform_(k)\nwea = nn.Parameter(we)\nprint(wea)\nwa = wea\nfor i in range(4-1):\n    wa = torch.cat((wa,wea),0)\nx = torch.rand(4,20,4)\n#wa = nn.Parameter(wa)\ne = torch.bmm(x,wa)/math.sqrt(hidden)\nprint(wa)\nprint('*'*40)\nprint(e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"e.grad_fn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xr = torch.rand(4,300,1)\nprint(xr)\nprint(xr.transpose(1,2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod.att.we","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class attention(nn.Module):\n    def __init__(self,batch_size,hidden_size=50,max_len=300):\n        super().__init__()\n        k = torch.zeros(1,2*hidden_size,1)\n        torch.nn.init.kaiming_uniform_(k).to(device)\n        self.we = nn.Parameter(k).to(device)\n        w = self.we\n        for i in range(batch_size-1):\n            w = torch.cat((w,self.we),0)\n        self.w = w.to(device)\n        self.hidden = hidden_size\n        self.max_len = max_len\n        self.e=0\n        self.att_weights=0\n        self.out=0\n    def forward(self,x):\n        #e = torch.mm(x.view(-1,2*hidden_size),self.w).view(-1,max_len,1)\n        # x.shape = (batch_size,max_len,2*hidden_size), w.shape = (2*hidden_size,1)\n        # e.shape = (batch_size,max_len,1)\n        # later on also try with w.shape = (batch_size,2*hidden,1) ; use torch.bmm(x,w) in that case instead of above np.dot implementation\n        self.e = torch.bmm(x,self.w)/math.sqrt(self.hidden)\n        self.tanh = torch.tanh(self.e)\n        self.att_weights = F.softmax(self.tanh,dim=1) # attention weights shape = (batch_size,max_len,1)\n        self.out = torch.bmm(self.att_weights.transpose(1,2),x)\n        return self.out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = attention(100,300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = torch.rand(4,300,100)\na(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"w = torch.zeros(100,1)\nnn.init.kaiming_uniform_(w)\nwe = nn.Parameter(w)\nprint(we)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"b = nn.Parameter(torch.ones(300))\nprint(b)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xfl = torch.rand(4,300,100)\nprint(xfl)\nprint(xfl.contiguous().view(-1, 100))\ne = torch.mm(\n            xfl.contiguous().view(-1, 100), \n            we\n        )\nprint(e)\nprint(e.shape)\ne = e.view(-1, 300)\nprint(e)\ne = e+b\nprint(e)\nth = torch.tanh(e)\nprint(th)\na = torch.exp(th)\nprint(a)\nprint('a shape : ',a.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(torch.sum(a, 1, keepdim=True))\na = a/torch.sum(a, 1, keepdim=True)\nprint(a)\nprint(a.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xfl.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(torch.unsqueeze(a, -1).shape)\nprint(xfl * torch.unsqueeze(a, -1).shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class attention(nn.Module):\n    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n        super(attention, self).__init__(**kwargs)\n        \n        self.supports_masking = True\n\n        self.bias = bias\n        self.feature_dim = feature_dim\n        self.step_dim = step_dim\n        self.features_dim = 0\n        self.a = 0\n        self.th = 0\n        self.eij = 0\n        \n        weight = torch.zeros(feature_dim, 1)\n        nn.init.kaiming_uniform_(weight)\n        self.weight = nn.Parameter(weight)\n        print('weight : ',self.weight)\n        print('weight shape : ',weight.shape)\n        \n        if bias:\n            self.b = nn.Parameter(torch.zeros(step_dim))\n        print('bias shape : ',self.b.shape)\n        \n    def forward(self, x, mask=None):\n        feature_dim = self.feature_dim \n        step_dim = self.step_dim\n#         print('x shape : ',x.shape)\n\n        self.eij = torch.mm(\n            x.contiguous().view(-1, feature_dim), \n            self.weight\n        ).view(-1, step_dim)\n        \n#         print('eij shape : ',self.eij.shape)\n        \n        if self.bias:\n            self.eij = self.eij + self.b\n            \n        self.th = torch.tanh(self.eij)\n#         print('tanh out shape : ',self.th.shape)\n        a = torch.exp(self.th)\n#         print('a shape : ',a.shape)\n        \n        if mask is not None:\n            a = a * mask\n\n        self.a = a / (torch.sum(a, 1, keepdim=True) + 1e-10)\n#         print('a divided by sum shape : ',self.a.shape)\n\n        weighted_input = x * torch.unsqueeze(self.a, -1)\n#         print('weighted input : ',weighted_input.shape)\n        return torch.sum(weighted_input, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = torch.rand(4,300)\na = torch.unsqueeze(a,-1)\ne = x*a\ntorch.sum(e,1).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feed forward of main task\nclass feedforward1(nn.Module):\n    def __init__(self,data):\n        super().__init__()\n        \n        n = 3 if data=='sci' else 6\n        drop = 0.2 if data == 'sci' else 0.3\n            \n        self.drop = nn.Dropout(p=drop)\n        self.lin = nn.Linear(100,20)\n        self.relu = torch.nn.ReLU()\n        self.out = nn.Linear(20,n)\n    def forward(self,x):\n        x = self.drop(x)\n        lin_out = self.lin(x)\n        x = self.relu(lin_out)\n        x = self.out(x)\n        return (x,lin_out) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feed forward of section scaffold\nclass feedforward2(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.drop = nn.Dropout(p=0.3)\n        self.lin = nn.Linear(100,20)\n        self.relu = torch.nn.ReLU()\n        self.out = nn.Linear(20,5)\n    def forward(self,x):\n        x = self.drop(x)\n        lin_out = self.lin(x)\n        x = self.relu(lin_out)\n        x = self.out(x)\n        return (x,lin_out) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feed forward of citation worthiness scaffold\nclass feedforward3(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.drop = nn.Dropout(p=0.3)\n        self.lin = nn.Linear(100,20)\n        self.relu = torch.nn.ReLU()\n        self.out = nn.Linear(20,2)\n    def forward(self,x):\n        x = self.drop(x)\n        lin_out = self.lin(x)\n        x = self.relu(lin_out)\n        x = self.out(x)\n        return (x,lin_out) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feed forward of citance + cited title scaffold\nclass feedforward4(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.drop = nn.Dropout(p=0.3)\n        self.lin = nn.Linear(100,20)\n        self.relu = torch.nn.ReLU()\n        self.out = nn.Linear(20,6)\n    def forward(self,x):\n        x = self.drop(x)\n        lin_out = self.lin(x)\n        x = self.relu(lin_out)\n        x = self.out(x)\n        return (x,lin_out) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class modelv3(nn.Module):\n    def __init__(self,batch_size):\n        super().__init__()\n        self.batch_size = batch_size\n        self.BertModel = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n        self.lstm = nn.LSTM(768,50,num_layers=1,bidirectional=True,batch_first=True)\n#         self.att = attention(batch_size)\n        self.att = attention(100,300)\n        self.main_sci = feedforward1(data='sci')\n        self.main_pk = feedforward1(data='pk')\n        self.sec = feedforward2()\n        self.cit = feedforward3()\n        self.cited = feedforward4()\n    def forward(self,x,n,data=None):\n        xbert=self.BertModel(x)\n        lstm,_=self.lstm(xbert[0])\n        at = self.att(lstm)\n        if(n==1 and data=='sci'):\n            return self.main_sci(at)[0]\n        \n        elif(n==1 and data=='pk'):\n            return self.main_pk(at)[0]\n        \n        elif(n==2):\n            return self.sec(at)[0]\n        \n        elif(n==3):\n            return self.cit(at)[0]\n        elif(n==4):\n            return self.cited(at)[0]\n        else:\n            # predicting == training done!!\n            if(data=='sci'):\n                z,last = self.main_sci(at)\n                _,last_sec = self.sec(at)\n                _,last_cit = self.cit(at)\n                z = F.softmax(z,dim=1)\n                z = torch.argmax(z,dim=1) \n                return (z,last,at,last_cit,last_sec,lstm)\n            else:\n                z,last = self.main_pk(at)\n                _,last_sec = self.sec(at)\n                _,last_cit = self.cit(at)\n                _,last_cited = self.cited(at)\n                z = F.softmax(z,dim=1)\n                z = torch.argmax(z,dim=1)\n                return (z,last,at,last_cit,last_sec,last_cited,lstm)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"modelv3(4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **DATA INPUT**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# validation data\nvm=[]\nwith jsonlines.open(val_main) as f:\n    for line in f.iter():\n        vm.append(line)\npdvm = pd.DataFrame(vm)\npdvm        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"citvm=pdvm['string'].values.tolist()\ncitvm = [fun(i) for i in citvm]\npdvm['processed_text'] = citvm\nyc = pdvm['label'].values.tolist()\nlabel={'background':0,'method':1,'result':2}\nvy = list(map(lambda t : label[t],yc))\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\nvx = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=300),citvm))\nvy = torch.tensor(vy)\nvx = torch.tensor(vx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vy.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test data\ntestm=[]\nwith jsonlines.open(test_main) as f:\n    for line in f.iter():\n        testm.append(line)\npdtm = pd.DataFrame(testm)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pdtm.loc[pdtm['string'] == 'Moreover, in our analyses, the antibody responses to vaccination were also analyzed separately and our 12-week follow-up to record the immune response to vaccination was much longer than those reported from previous studies where reduction in immunity can be observed (Kiecolt-Glaser et al. 1996; Glaser et al. 1999; Vedhara et al. 1999).']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cittem=pdtm['string'].values.tolist()\ncittem = [fun(i) for i in cittem]\npdtm['processed_text'] = cittem\ncittem = cittem[:-1]\nyc = pdtm[:-1]['label'].values.tolist()\nlabel={'background':0,'method':1,'result':2}\nty = list(map(lambda t : label[t],yc))\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\ntx = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=300),cittem))\nty = torch.tensor(ty)\ntx = torch.tensor(tx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tx.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in val_data:\n    print(i[0].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batchSize = 12\nnum_of_feedforwards = 3\n#model = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\nmain_tr = torch.utils.data.TensorDataset(x, y)\nmain_val = torch.utils.data.TensorDataset(vx, vy)\nmain_test = torch.utils.data.TensorDataset(tx, ty)\nsec_tr = torch.utils.data.TensorDataset(xsec,ysec)\ncit_tr = torch.utils.data.TensorDataset(xcit,ycit)\n#tit_tr = torch.utils.data.TensorDataset(x_tit,y_tit)\n\n \ntrain_sampler = torch.utils.data.RandomSampler(main_tr)\ntrain_data = torch.utils.data.DataLoader(main_tr, sampler=train_sampler, batch_size=batchSize//num_of_feedforwards)\n\ntrain_sampler = torch.utils.data.RandomSampler(sec_tr)\nsec_data = torch.utils.data.DataLoader(sec_tr, sampler=train_sampler, batch_size=batchSize//num_of_feedforwards)\n\ntrain_sampler = torch.utils.data.RandomSampler(cit_tr)\ncit_data = torch.utils.data.DataLoader(cit_tr, sampler=train_sampler, batch_size=batchSize//num_of_feedforwards)\n\nval_sampler = torch.utils.data.RandomSampler(main_val)\nval_data = torch.utils.data.DataLoader(main_val, sampler=val_sampler, batch_size=batchSize//num_of_feedforwards)\n\ntest_sampler = torch.utils.data.RandomSampler(main_test)\ntest_data = torch.utils.data.DataLoader(main_test, sampler=test_sampler, batch_size=batchSize//num_of_feedforwards)\n\n# train_sampler = torch.utils.data.RandomSampler(tit_tr)\n# tit_data = torch.utils.data.DataLoader(tit_tr, sampler=train_sampler, batch_size=batchSize//num_of_feedforwards)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Training**"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"mod = torch.load('../input/cohan-finetuned-on-acl/cohan_model_finetuned_acl_without_freezing_ep20.pt')\nmod.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"print(list(mod.parameters())[0].grad)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name,param in mod.named_parameters():\n    if(name.split('.')[0] == 'main_pk' or name.split('.')[0] == 'cited'):\n        print(name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(list(mod.named_parameters())[-13][1].grad)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"mod = torch.load('../input/cohan-v3-models/cohan_modelv3_ep6.pt')\nmod.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_grad_flow(named_parameters):\n    ave_grads = []\n    layers = []\n    for n, p in named_parameters:\n        if(p.requires_grad) and (\"bias\" not in n):\n            layers.append(n)\n            ave_grads.append(p.grad.abs().mean())\n    plt.plot(ave_grads, alpha=0.3, color=\"b\")\n    plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n    plt.xlim(xmin=0, xmax=len(ave_grads))\n    plt.xlabel(\"Layers\")\n    plt.ylabel(\"average gradient\")\n    plt.title(\"Gradient flow\")\n    plt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"for name,i in mod.named_parameters():\n    try:\n        print(i.grad.device,name)\n    except:\n        pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#training for models\n# mod=modelv3(batchSize//num_of_feedforwards)\nmod.to(device)\n\nfor name,param in mod.named_parameters():\n    if(name.split('.')[0] == 'main_pk' or name.split('.')[0] == 'cited'):\n        param.requires_grad = False\n\nlambd1 = 0.05   #lambd1 for influence of section scaffold\nlambd2 = 0.1    #lambd2 for influence of citation worthiness scaffold\n#lambd3 = 0.1    #lambd3 for influence of cited paper title scaffold\n\nloss = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adadelta(mod.parameters(), lr = 0.01)\n\nloss_list = []\nf1_list = []\n\nfor epoch in range(3,6):\n    running_loss = 0\n    ypr=[]\n    ytr=[]\n    y_eval=[]\n    ypr_eval=[]\n    \n    print(f'gradients before epoch{epoch+1} : ')\n    print('main_pk out :')\n    print(list(mod.named_parameters())[-13][1].grad)\n    print('main_sci out :')\n    print(list(mod.named_parameters())[-17][1].grad)\n    \n# training--------------------\n    mod.train()\n#     print(mod.att.att_weights.requires_grad)\n#     print(mod.att.out.requires_grad)\n    for i,data in enumerate(zip(train_data,sec_data,cit_data)):\n        m = data[0]\n        s = data[1]\n        c = data[2]\n       # t = data[3]\n        \n        in_main,tar_main = m[0].to(device),m[1].to(device)\n        in_sec,tar_sec = s[0].to(device),s[1].to(device)\n        in_cit,tar_cit = c[0].to(device),c[1].to(device)\n        #in_tit,tar_tit = t[0].to(device),t[1].to(device)\n        \n        optimizer.zero_grad()\n        \n        main = mod(in_main,1,'sci')\n        sec = mod(in_sec,2)\n        cit = mod(in_cit,3)\n        #tit = mod(in_cit,4)\n        \n        loss_main = loss(main,tar_main)\n        loss_sec = loss(sec,tar_sec)\n        loss_cit = loss(cit,tar_cit)\n        #loss_tit = loss(tit,tar_tit)\n\n        overall_loss = (loss_main + lambd1*loss_sec + lambd2*loss_cit)/num_of_feedforwards  # becoz initially the summation is avg loss per mini batch(8) but we need avg loss per mini batch(24)\n        overall_loss.backward()\n        torch.nn.utils.clip_grad_norm_(mod.parameters(), 5)\n#         plot_grad_flow(mod.named_parameters())\n        optimizer.step()\n        \n        running_loss += overall_loss.item()\n        if(i%100 == 99):\n            loss_list.append({'epoch':epoch+1,'batch':i+1,'loss':round(running_loss / 100,3)})\n            print('[epoch : %d,batch : %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n            \n#             print('gradients : ')\n#             print('main_sci out :')\n#             print(list(mod.named_parameters())[-13][1].grad)\n#             print('main_pk out :')\n#             print(list(mod.named_parameters())[-9][1].grad)\n#             print('#'*50)\n            running_loss = 0.0\n   \n# validation ------------------------\n    with torch.no_grad():\n        mod.eval()\n        \n        # calculating f1_score for train data\n        for d in train_data:\n            x = d[0].to(device)\n            y = d[1].to(device)\n            for yt in y.cpu():\n                ytr.append(yt)\n            y_pred = mod(x,0,'sci')[0].cpu()\n            for yt in y_pred:\n                ypr.append(yt)\n                \n        f1 = f1_score(ytr,ypr,average='macro')\n        \n        # calculating f1_score for validation data\n        for d in val_data:\n            xv = d[0].to(device)\n            yv = d[1].to(device)\n            for yt in yv.cpu():\n                y_eval.append(yt)\n            y_pred = mod(xv,0,'sci')[0].cpu()\n            for yt in y_pred:\n                ypr_eval.append(yt)\n                \n        val_f1 = f1_score(y_eval,ypr_eval,average='macro')\n        \n        f1_list.append({'epoch':epoch+1,'train_f1_score':f1,'val_f1_score':val_f1})\n        \n    print('*'*40)\n    print('train confusion matrix : ')\n    print(confusion_matrix(ytr, ypr))\n    print('*'*40)\n    print('val confusion matrix : ')\n    print(confusion_matrix(y_eval, ypr_eval))\n    print('*'*40)\n    print('[epoch : %d] train_f1_macro: %.3f, val_f1_macro: %.3f' %(epoch+1, f1, val_f1))\n    print('*'*40)\n    torch.save(mod, f'./cohan_modelv3_att_renew_same_w_dropout0.3_ep{epoch+1}.pt')\n    print('#'*40)\n    print('attention weight vector : ')\n    print(mod.att.weight)\n    print('attention eij : ')\n    print(mod.att.eij)\n    print('attention att weights : ')\n    print(mod.att.a)\n#     if((epoch+1)%2==0):\n#         torch.save(mod, f'./cohan_modelv3_ep{epoch+1}.pt')\n\nprint('Finished Training!!')  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FileLinks('./')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cittem","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tx = tokenizer.encode(cittem[0])\nlen(tx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod = torch.load('./cohan_modelv3_att_renew_same_w_dropout0.3_ep5.pt') ## cohan_modelv3_dropout_ep#.pt are the renewed attention layer models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cittem","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cittem=pdtm['string'].values.tolist()[0]\ncittem = [fun(cittem)]\n# pdtm['processed_text'] = cittem\nyc = pdtm['label'].values.tolist()[0]\nlabel={'background':0,'method':1,'result':2}\nty = label[yc]\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\ntx = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=300),cittem))\nty = torch.tensor(ty).view(1,-1)\ntx = torch.tensor(tx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ty","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"tx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = torch.cat((tx,tx,tx,tx),0)\ny = torch.cat((ty,ty,ty,ty),0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod.att.a","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod(xt,0,'sci')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xt = x.cuda()\nyt = y.cuda()\nlstm = mod(xt,0,'sci')[-1]\nprint('output : ',mod(xt,0,'sci')[0])\nprint('lstm : ',lstm.shape)\n# wei = mod.att.we\n# e = torch.bmm(lstm,wei)\ne = mod.att.eij\nprint(e.shape)\n# att_weights = F.softmax(e,dim=1)\natt_weights = mod.att.a\nprint(att_weights.shape)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n#sns.color_palette(\"coolwarm\")\naw = att_weights[0].view(-1,1).cpu().detach().numpy()\nprint(aw.shape)\naw = aw[:35]\nfig, ax = plt.subplots(figsize=(20, 1))\nsns.heatmap(aw.transpose(1,0),linewidths=.01,cmap=\"YlGnBu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aw","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"att_weights[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cittem","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from transformers import AutoTokenizer, AutoModel,convert_ids_to_tokens\ntokenizer.convert_ids_to_tokens(xt[3])[34]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"print(list(mod.named_parameters())[-9][1].grad)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.chdir(r'../working')\nfrom IPython.display import FileLink\nFileLink(r'./cohan_modelv3_ep4.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FileLink(r'./cohan_modelv3_ep6.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FileLink(r'./cohan_modelv3_ep8.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FileLink(r'./cohan_modelv3_ep10.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('weights before the start of training : ')\nfor name, param in mod.named_parameters():\n    if(name.split('.')[0]!='BertModel'):\n        print(name,param.data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Saving the model**"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"mod.state_dict()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"torch.save(mod, 'check_cohan_sci.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.chdir(r'../working')\nfrom IPython.display import FileLink\nFileLink(r'./cohan_model_finetuned_acl_without_freezing_ep45.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save({\n            'epoch': epoch,\n            'model_state_dict': mod.state_dict(),\n            'loss': overall_loss,\n            }\n            , './model_epoch4.tar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.cuda.memory_summary(device=None, abbreviated=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Test on acl-arc**"},{"metadata":{"trusted":true},"cell_type":"code","source":"mod = torch.load('./cohan_model_finetuned_acl_without_freezing_ep40.pt')\nmod.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batchSize = 12\nnum_of_feedforwards = 3\nmain_tr = torch.utils.data.TensorDataset(acl_x, acl_y)\nmain_test = torch.utils.data.TensorDataset(tx, ty)\ntrain_sampler = torch.utils.data.RandomSampler(main_tr)\ntrain_data = torch.utils.data.DataLoader(main_tr, sampler=train_sampler, batch_size=batchSize//num_of_feedforwards)\ntest_sampler = torch.utils.data.RandomSampler(main_test)\ntest_data = torch.utils.data.DataLoader(main_test, sampler=test_sampler, batch_size=batchSize//num_of_feedforwards)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test=[]\nypr_test=[]\nwith torch.no_grad():\n    mod.eval()\n    for d in test_data:\n        xte = d[0].to(device)\n        yte = d[1].to(device)\n        for yt in yte.cpu():\n            y_test.append(yt)\n        y_pred = mod(xte,0,'pk')[0].cpu()\n        for yt in y_pred:\n            ypr_test.append(yt)\n                \n    test_f1 = f1_score(y_test,ypr_test,average='macro')\n    print('test_f1_score : ',test_f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test=[]\nypr_test=[]\nwith torch.no_grad():\n    mod.eval()\n    for d in train_data:\n        xte = d[0].to(device)\n        yte = d[1].to(device)\n        for yt in yte.cpu():\n            y_test.append(yt)\n        y_pred = mod(xte,0,'pk')[0].cpu()\n        for yt in y_pred:\n            ypr_test.append(yt)\n                \n    test_f1 = f1_score(y_test,ypr_test,average='macro')\n    print('train_f1_score : ',test_f1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Models Loading for test on pride data**"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"mod_cohan_sci = torch.load('../input/cohan-model/full_model_epoch4.pth')\nmod_cohan_sci.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_v2 = torch.load('./full_modelv2_epoch_g4.pth')\nmodel_v2.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model_v3 = torch.load('../input/cohan-v3-models/cohan_modelv3_ep4.pt')\nmodel_v3.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"mod = torch.load('./cohan_modelv3_scaffold4_pk_ep18.pt')\nmod.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batchSize = 12\nnum_of_feedforwards = 3\nmain_test = torch.utils.data.TensorDataset(tx, ty)\ntest_sampler = torch.utils.data.RandomSampler(main_test)\ntest_data = torch.utils.data.DataLoader(main_test, sampler=test_sampler, batch_size=batchSize//num_of_feedforwards)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test=[]\nypr_test=[]\nwith torch.no_grad():\n    mod.eval()\n    for d in test_data:\n        xte = d[0].to(device)\n        yte = d[1].to(device)\n        for yt in yte.cpu():\n            y_test.append(yt)\n        y_pred = model_v3(xte,0,'sci')[0].cpu()\n        for yt in y_pred:\n            ypr_test.append(yt)\n                \n    test_f1 = f1_score(y_test,ypr_test,average='macro')\n    print('test_f1_score : ',test_f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test=[]\nypr_test=[]\nwith torch.no_grad():\n    mod.eval()\n    for d in train_data:\n        xte = d[0].to(device)\n        yte = d[1].to(device)\n        for yt in yte.cpu():\n            y_test.append(yt)\n        y_pred = model_v3(xte,0,'sci')[0].cpu()\n        for yt in y_pred:\n            ypr_test.append(yt)\n                \n    test_f1 = f1_score(y_test,ypr_test,average='macro')\n    print('test_f1_score : ',test_f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test1 = [y.item() for y in y_test]\npd.Series(y_test1).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ypr_test1 = [y.item() for y in ypr_test]\npd.Series(ypr_test1).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pdtr = pd.read_csv('../input/pride-data/train.csv')\npdte = pd.read_csv('../input/pride-data/test.csv')\npdtr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pdtr['citation_class_label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pdtr.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pdte['citation_context'][29]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pdte['cited_title'][29]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grp = pdtr.groupby('citing_author')\nfor aut,inst in grp:\n    print(aut)\n    print(inst[['unique_id','citation_context','citation_class_label']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pdtr.iloc[[619,620]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pdtr.iloc[619]['citation_context'] #label : 0 = 'BACKGROUND' = so same sentence as in index 620 but diff. classification of citation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pdtr.iloc[620]['citation_context'] #label : 1 = 'COMPARES_CONTRASTS' = so same sentence as in index 619 but diff. classification of citation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(pdtr['citation_class_label'].values.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prtr = list(map(lambda t : t[:t.find('#AUTHOR_TAG')]+t[t.find('#AUTHOR_TAG')+11:],pdtr['citation_context']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(pdtr['citation_context'].values.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(prtr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prtr = list(map(lambda t : t[:t.find('#AUTHOR_TAG')]+t[t.find('#AUTHOR_TAG')+11:],pdtr['citation_context']))\nyc = pdtr['citation_class_label'].values.tolist()\nlabel={0:0,1:2,2:0,3:0,4:0,5:1}\nty = list(map(lambda t : label[t],yc))\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\ntx = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=300),prtr))\nty = torch.tensor(ty)\ntx = torch.tensor(tx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tx.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ty.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batchSize = 12\nnum_of_feedforwards = 3\npride_test = torch.utils.data.TensorDataset(tx, ty)\nprtest_sampler = torch.utils.data.RandomSampler(pride_test)\nprtest_data = torch.utils.data.DataLoader(pride_test, sampler=prtest_sampler, batch_size=batchSize//num_of_feedforwards)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=[]\nypredict=[]\nwith torch.no_grad():\n    mod.eval()\n    for d in prtest_data:\n        xte = d[0].to(device)\n        yte = d[1].to(device)\n        for yt in yte.cpu():\n            y.append(yt)\n        y_pred = mod(xte,0,'pk')[0].cpu()\n        for yt in y_pred:\n            ypredict.append(yt)\n                \n    test_f1 = f1_score(y,ypredict,average='macro')\n    print('pride_f1_score : ',test_f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"y1 = [y.item() for y in y]\npd.Series(y1).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"ypredict1 = [y.item() for y in ypredict]\npd.Series(ypredict1).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=[]\nypredict=[]\nwith torch.no_grad():\n    model_c.eval()\n    for d in prtest_data:\n        xte = d[0].to(device)\n        yte = d[1].to(device)\n        for yt in yte.cpu():\n            y.append(yt)\n        y_pred = model_c(xte,0).cpu()\n        for yt in y_pred:\n            ypredict.append(yt)\n                \n    test_f1 = f1_score(y,ypredict,average='macro')\n    print('pride_f1_score : ',test_f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pride data prep for model v1\n\ncitm=pdtr['citation_context'].values.tolist()\n\nyc = pdtr['citation_class_label'].values.tolist()\n# label={0:0,1:2,2:1,3:0,4:0,5:1}\n# y = list(map(lambda t : label[t],yc))\n\nx_cit = datac['cleaned_cite_text'].values.tolist()\n\nycit = datac['is_citation'].values.tolist()\nycit_ie = list(map(lambda x : int(x),ycit))\n\nx_sec = data['text'].values.tolist()\n\ny_sec = data['section_name'].values.tolist()\nlabels={'introduction':0,'related work':1,'method':2,'experiments':3,'conclusion':4}\nysec_ie = list(map(lambda t : labels[t],y_sec))\n\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\nx = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=100),citm))\n\ny = torch.tensor(yc)\nx = torch.tensor(x)\nvx = x[2600:]\nvy = y[2600:]\nx=x[:2600]\ny=y[:2600]\nprint(x.shape)\nprint(y.shape)\n\n\n\nxcit = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=100),x_cit))\nxsec = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=100),x_sec))\n\nsec = [(x,y) for x,y in zip(xsec,ysec_ie)]\nsec = random.sample(sec, 2600)\n\ncit = [(x,y) for x,y in zip(xcit,ycit_ie)]\ncit = random.sample(cit, 2600)\n\nxcit = torch.tensor([t[0] for t in cit])\nycit = torch.tensor([t[1] for t in cit])\nxsec = torch.tensor([t[0] for t in sec])\nysec = torch.tensor([t[1] for t in sec])\nprint(xsec.shape)\nprint(xcit.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pride data prep for model v2\nx_tit = pdtr['cited_title'].values.tolist()\n\nyc = pdtr['citation_class_label'].values.tolist()\nlabel={0:0,1:2,2:1,3:0,4:0,5:1}\ny_tit = list(map(lambda t : label[t],yc))\n\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\nx_tit = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=70),x_tit))\ntit = [(x,y) for x,y in zip(x_tit,y_tit)]\ntit = random.sample(tit, 2600)\n\nx_tit = torch.tensor([t[0] for t in tit])\ny_tit = torch.tensor([t[1] for t in tit])\n\nprint(x_tit.shape)\nprint(y_tit.shape)\n\n\ncitm=pdtr['citation_context'].values.tolist()\n\nyc = pdtr['citation_class_label'].values.tolist()\nlabel={0:0,1:2,2:1,3:0,4:0,5:1}\ny = list(map(lambda t : label[t],yc))\n\nx_cit = datac['cleaned_cite_text'].values.tolist()\n\nycit = datac['is_citation'].values.tolist()\nycit_ie = list(map(lambda x : int(x),ycit))\n\nx_sec = data['text'].values.tolist()\n\ny_sec = data['section_name'].values.tolist()\nlabels={'introduction':0,'related work':1,'method':2,'experiments':3,'conclusion':4}\nysec_ie = list(map(lambda t : labels[t],y_sec))\n\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\nx = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=70),citm))\n\ny = torch.tensor(y)\nx = torch.tensor(x)\nvx = x[2600:]\nvy = y[2600:]\nx=x[:2600]\ny=y[:2600]\nprint(x.shape)\nprint(y.shape)\n\n\nxcit = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=70),x_cit))\nxsec = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=70),x_sec))\n\nsec = [(x,y) for x,y in zip(xsec,ysec_ie)]\nsec = random.sample(sec, 2600)\n\ncit = [(x,y) for x,y in zip(xcit,ycit_ie)]\ncit = random.sample(cit, 2600)\n\nxcit = torch.tensor([t[0] for t in cit])\nycit = torch.tensor([t[1] for t in cit])\nxsec = torch.tensor([t[0] for t in sec])\nysec = torch.tensor([t[1] for t in sec])\nprint(xsec.shape)\nprint(xcit.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batchSize = 12\nnum_of_feedforwards = 3  # 4 for v2 model and 3 for v1 model\n\n#model = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n\nmain_tr = torch.utils.data.TensorDataset(x, y)\nmain_val = torch.utils.data.TensorDataset(vx, vy)\nsec_tr = torch.utils.data.TensorDataset(xsec,ysec)\ncit_tr = torch.utils.data.TensorDataset(xcit,ycit)\n#tit_tr = torch.utils.data.TensorDataset(x_tit,y_tit)\n \ntrain_sampler = torch.utils.data.RandomSampler(main_tr)\ntrain_data = torch.utils.data.DataLoader(main_tr, sampler=train_sampler, batch_size=batchSize//num_of_feedforwards)\n\ntrain_sampler = torch.utils.data.RandomSampler(sec_tr)\nsec_data = torch.utils.data.DataLoader(sec_tr, sampler=train_sampler, batch_size=batchSize//num_of_feedforwards)\n\ntrain_sampler = torch.utils.data.RandomSampler(cit_tr)\ncit_data = torch.utils.data.DataLoader(cit_tr, sampler=train_sampler, batch_size=batchSize//num_of_feedforwards)\n\nval_sampler = torch.utils.data.RandomSampler(main_val)\nval_data = torch.utils.data.DataLoader(main_val, sampler=val_sampler, batch_size=batchSize//num_of_feedforwards)\n\n# train_sampler = torch.utils.data.RandomSampler(tit_tr)\n# tit_data = torch.utils.data.DataLoader(tit_tr, sampler=train_sampler, batch_size=batchSize//num_of_feedforwards)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_c.parameters()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod=model(batchSize//3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_c.state_dict()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod.state_dict()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for param in mod.parameters():\n    print(type(param), param.size())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_c.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training of v1 models on pride data\n\n#mod=model(batchSize//3)\nmod.to(device)\n\nlambd1 = 0.05   #lambd1 for influence of section scaffold\nlambd2 = 0.05    #lambd2 for influence of citation worthiness scaffold\n\n# loss = torch.nn.CrossEntropyLoss()\n# optimizer = torch.optim.Adadelta(mod.parameters(), lr = 0.01)\n\nloss_list = []\nf1_list = []\n\nfor epoch in range(10):\n    running_loss = 0\n    ypr=[]\n    ytr=[]\n    y_eval=[]\n    ypr_eval=[]\n \n# training--------------------\n    mod.train()\n    for i,data in enumerate(zip(train_data,sec_data,cit_data)):\n        m = data[0]\n        s = data[1]\n        c = data[2]\n        \n        in_main,tar_main = m[0].to(device),m[1].to(device)\n        in_sec,tar_sec = s[0].to(device),s[1].to(device)\n        in_cit,tar_cit = c[0].to(device),c[1].to(device)\n        \n        optimizer.zero_grad()\n        \n        main = mod(in_main,1,'pk')\n        sec = mod(in_sec,2)\n        cit = mod(in_cit,3)\n        \n        loss_main = loss(main,tar_main)\n        loss_sec = loss(sec,tar_sec)\n        loss_cit = loss(cit,tar_cit)\n\n        overall_loss = (loss_main + lambd1*loss_sec + lambd2*loss_cit)/num_of_feedforwards  # becoz initially the summation is avg loss per mini batch(8) but we need avg loss per mini batch(24)\n        overall_loss.backward()\n        torch.nn.utils.clip_grad_norm_(mod.parameters(), 5)\n        optimizer.step()\n        \n        running_loss += overall_loss.item()\n        if(i%100 == 99):\n            loss_list.append({'epoch':epoch+1,'batch':i+1,'loss':round(running_loss / 100,3)})\n            print('[epoch : %d,batch : %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n            running_loss = 0.0\n   \n# validation ------------------------\n    with torch.no_grad():\n        mod.eval()\n        \n        # calculating f1_score for train data\n        for d in train_data:\n            x = d[0].to(device)\n            y = d[1].to(device)\n            for yt in y.cpu():\n                ytr.append(yt)\n            y_pred = mod(x,0,'pk').cpu()\n            for yt in y_pred:\n                ypr.append(yt)\n                \n        f1 = f1_score(ytr,ypr,average='macro')\n        \n        # calculating f1_score for validation data\n        for d in val_data:\n            xv = d[0].to(device)\n            yv = d[1].to(device)\n            for yt in yv.cpu():\n                y_eval.append(yt)\n            y_pred = mod(xv,0,'pk').cpu()\n            for yt in y_pred:\n                ypr_eval.append(yt)\n                \n        val_f1 = f1_score(y_eval,ypr_eval,average='macro')\n        \n        f1_list.append({'epoch':epoch+1,'train_f1_score':f1,'val_f1_score':val_f1})\n    \n    print('*'*40)\n    print('[epoch : %d] train_f1_macro: %.3f, val_f1_macro: %.3f' %(epoch+1, f1, val_f1))\n    print('*'*40)\n\nprint('Finished Training!!')            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(mod, './full_model_v1_epoch32_ml100.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"mod = torch.load('./cohan_modelv3_scaffold4_pk_ep20.pt')\nmod.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Submission file generation\n\nprte = list(map(lambda t : t[:t.find('#AUTHOR_TAG')]+t[t.find('#AUTHOR_TAG')+11:],pdte['citation_context']))\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\ntx = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=250),prte))\ntx = torch.tensor(tx)\n\nind = list(pdte['unique_id'])\n\npred = []\nwith torch.no_grad():\n    mod.eval()\n    for i in range(0,len(tx),4):\n        l=[]\n        x = tx[i:i+4]\n        idx = ind[i:i+4]\n        x = x.to(device)\n        y_pr = mod(x,0,'pk')[0].cpu()\n        for j in range(len(x)):\n            l = [idx[j],y_pr[j].item()]\n            pred.append(l)\n        \ndf = pd.DataFrame(pred, columns = ['unique_id', 'citation_class_label']) \ndf.set_index('unique_id', inplace = True)\n\nprint(df)\ndf.to_csv('./submission1.csv') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = [i[1] for i in pred]        #ep24 with SMOTE\npd.Series(p).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p = [i[1] for i in pred]          #ep20 without SMOTE\npd.Series(p).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod(x,0,'pk')[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for d in train_data:\n    print(d[0].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Training of v2 models on pride data\n\n#mod=model(batchSize//3)\nmod.to(device)\n\nlambd1 = 0.05   #lambd1 for influence of section scaffold\nlambd2 = 0.1    #lambd2 for influence of citation worthiness scaffold\nlambd3 = 0.1    #lambd3 for influence of cited paper title scaffold\n\nloss = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adadelta(mod.parameters(), lr = 0.01)\n\nloss_list = []\nf1_list = []\n\nfor epoch in range(2):\n    running_loss = 0\n    ypr=[]\n    ytr=[]\n    y_eval=[]\n    ypr_eval=[]\n \n# training--------------------\n    mod.train()\n    for i,data in enumerate(zip(train_data,sec_data,cit_data,tit_data)):\n        m = data[0]\n        s = data[1]\n        c = data[2]\n        t = data[3]\n        \n        in_main,tar_main = m[0].to(device),m[1].to(device)\n        in_sec,tar_sec = s[0].to(device),s[1].to(device)\n        in_cit,tar_cit = c[0].to(device),c[1].to(device)\n        in_tit,tar_tit = t[0].to(device),t[1].to(device)\n        \n        optimizer.zero_grad()\n        \n        main = mod(in_main,1)\n        sec = mod(in_sec,2)\n        cit = mod(in_cit,3)\n        tit = mod(in_tit,4)\n        \n        loss_main = loss(main,tar_main)\n        loss_sec = loss(sec,tar_sec)\n        loss_cit = loss(cit,tar_cit)\n        loss_tit = loss(tit,tar_tit)\n\n        overall_loss = (loss_main + lambd1*loss_sec + lambd2*loss_cit + lambd3*loss_tit)/num_of_feedforwards  # becoz initially the summation is avg loss per mini batch(8) but we need avg loss per mini batch(24)\n        overall_loss.backward()\n        torch.nn.utils.clip_grad_norm_(mod.parameters(), 5)\n        optimizer.step()\n        \n        running_loss += overall_loss.item()\n        if(i%100 == 99):\n            loss_list.append({'epoch':epoch+1,'batch':i+1,'loss':round(running_loss / 100,3)})\n            print('[epoch : %d,batch : %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n            running_loss = 0.0\n   \n# validation ------------------------\n    with torch.no_grad():\n        mod.eval()\n        \n        # calculating f1_score for train data\n        for d in train_data:\n            x = d[0].to(device)\n            y = d[1].to(device)\n            for yt in y.cpu():\n                ytr.append(yt)\n            y_pred = mod(x,0).cpu()\n            for yt in y_pred:\n                ypr.append(yt)\n                \n        f1 = f1_score(ytr,ypr,average='macro')\n        \n        # calculating f1_score for validation data\n        for d in val_data:\n            xv = d[0].to(device)\n            yv = d[1].to(device)\n            for yt in yv.cpu():\n                y_eval.append(yt)\n            y_pred = mod(xv,0).cpu()\n            for yt in y_pred:\n                ypr_eval.append(yt)\n                \n        val_f1 = f1_score(y_eval,ypr_eval,average='macro')\n        \n        f1_list.append({'epoch':epoch+1,'train_f1_score':f1,'val_f1_score':val_f1})\n    \n    print('*'*40)\n    print('[epoch : %d] train_f1_macro: %.3f, val_f1_macro: %.3f' %(epoch+1, f1, val_f1))\n    print('*'*40)\n\nprint('Finished Training!!')            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model_c, './full_model_v1_pk_ep8.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('./')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **4 scaffolds model - (for pk and acl)**"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"pdtr = pd.read_csv('../input/pride-data/train.csv')\npdte = pd.read_csv('../input/pride-data/test.csv')\npdtr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# code for combining citance and cited title to feed to simp_model\n\nprtr = list(map(lambda t : t[:t.find('#AUTHOR_TAG')]+t[t.find('#AUTHOR_TAG')+11:],pdtr['citation_context']))\nyc = pdtr['citation_class_label'].values.tolist()\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\nx = list(map(lambda t : tokenizer.encode(t),prtr))\nx_cited = list(map(lambda t : tokenizer.encode(t[0],padding=True,pad_to_max_length=True,max_length=251-len(t[1]))[1:],zip(pdtr['cited_title'],x)))\nx1 = [x+y for x,y in zip(x,x_cited)]\ny = torch.tensor(yc)\nx1 = torch.tensor(x1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prtr = list(map(lambda t : t[:t.find('#AUTHOR_TAG')]+t[t.find('#AUTHOR_TAG')+11:],pdtr['citation_context']))\nx = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=250),prtr))\nx = torch.tensor(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vx = x[2600:]\nvy = y[2600:]\nx=x[:2600]\nx1 = x1[:2600]\ny=y[:2600]\nprint(x.shape)\nprint(vx.shape)\nprint(x1.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(y).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# only oversampling of minority classes done for now!!!\nsampling_strategy = {0:1447,1:600,2:600,3:600,4:600,5:600}  # use this if u wnat to undersample using RandomUnderSampler after oversampling by SMOTE\ntr_over = SMOTE(sampling_strategy=sampling_strategy)\ntr_under = RandomUnderSampler(sampling_strategy={0:600,1:600,2:600,3:600,4:600,5:600})\nx_smote,y_smote = tr_over.fit_sample(x,y)\nx_smote,y_smote = tr_under.fit_sample(x_smote,y_smote)\n\nx1_smote,y_smote = tr_over.fit_sample(x1,y)\nx1_smote,y_smote = tr_under.fit_sample(x1_smote,y_smote)\nprint(Counter(y_smote))\n\nsampling_strategy = {0:201,1:100,2:100,3:100,4:100,5:100} # use this if u want to undersample as well after oversampling by SMOTE is done\n# while using above dict for sampling strategy of SMOTE, put k_neighbors = 4\nval_over = SMOTE(sampling_strategy=sampling_strategy,k_neighbors = 3)\nval_under = RandomUnderSampler(sampling_strategy={0:100,1:100,2:100,3:100,4:100,5:100})\nvx_smote,vy_smote = val_over.fit_sample(vx,vy)\nvx_smote,vy_smote = val_under.fit_sample(vx_smote,vy_smote)\nprint(Counter(vy_smote))\n\nx_smote = torch.tensor(x_smote)\ny_smote = torch.tensor(y_smote)\nvx_smote = torch.tensor(vx_smote)\nvy_smote = torch.tensor(vy_smote)\nx1_smote = torch.tensor(x1_smote)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# vx_smote = vx_smote[:-2]\n# vy_smote = vy_smote[:-2]\n# x_smote = x_smote[:-2]\n# x1_smote = x1_smote[:-2]\n# y_smote = y_smote[:-2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vx_smote.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(y).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batchSize = 8\nnum_of_feedforwards = 2  # 4 for v2 model and 3 for v1 model\n\n#model = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n\nmain_tr = torch.utils.data.TensorDataset(x_smote, y_smote)\nmain_val = torch.utils.data.TensorDataset(vx_smote, vy_smote)\n# sec_tr = torch.utils.data.TensorDataset(xsec,ysec)\n# cit_tr = torch.utils.data.TensorDataset(xcit,ycit)\ntit_tr = torch.utils.data.TensorDataset(x1_smote,y_smote)\n \ntrain_sampler = torch.utils.data.RandomSampler(main_tr)\ntrain_data = torch.utils.data.DataLoader(main_tr, sampler=train_sampler, batch_size=batchSize//num_of_feedforwards)\n\n# train_sampler = torch.utils.data.RandomSampler(sec_tr)\n# sec_data = torch.utils.data.DataLoader(sec_tr, sampler=train_sampler, batch_size=batchSize//num_of_feedforwards)\n\n# train_sampler = torch.utils.data.RandomSampler(cit_tr)\n# cit_data = torch.utils.data.DataLoader(cit_tr, sampler=train_sampler, batch_size=batchSize//num_of_feedforwards)\n\nval_sampler = torch.utils.data.RandomSampler(main_val)\nval_data = torch.utils.data.DataLoader(main_val, sampler=val_sampler, batch_size=batchSize//num_of_feedforwards)\n\ntrain_sampler = torch.utils.data.RandomSampler(tit_tr)\ntit_data = torch.utils.data.DataLoader(tit_tr, sampler=train_sampler, batch_size=batchSize//num_of_feedforwards)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod = torch.load('../input/cohan-v3-models/cohan_modelv3_ep4.pt')\nmod.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"mod.named_parameters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#training for models\n\n# mod.to(device)\n\nfor name,param in mod.named_parameters():\n    if(name.split('.')[0] == 'main_sci'):\n        param.requires_grad = False\n\nlambd1 = 0.05   #lambd1 for influence of section scaffold\nlambd2 = 0.1    #lambd2 for influence of citation worthiness scaffold\nlambd3 = 0.1    #lambd3 for influence of cited paper title scaffold\n\n# loss = torch.nn.CrossEntropyLoss()\n# optimizer = torch.optim.Adadelta(mod.parameters(), lr = 0.01)\n\nloss_list = []\nf1_list = []\n\nfor epoch in range(10):\n    running_loss = 0\n    ypr=[]\n    ytr=[]\n    y_eval=[]\n    ypr_eval=[]\n    \n    print(f'gradients before epoch{epoch+1} : ')\n    print('main_sci out :')\n    print(list(mod.named_parameters())[-17][1].grad)\n    print('main_pk out :')\n    print(list(mod.named_parameters())[-13][1].grad)\n    \n# training--------------------\n    mod.train()\n    for i,data in enumerate(zip(train_data,tit_data)):\n        m = data[0]\n        t = data[1]\n        \n        in_main,tar_main = m[0].to(device),m[1].to(device)\n        in_tit,tar_tit = t[0].to(device),t[1].to(device)\n        \n        optimizer.zero_grad()\n        \n        main = mod(in_main,1,'pk')\n        tit = mod(in_tit,4)\n        \n        loss_main = loss(main,tar_main)\n        loss_tit = loss(tit,tar_tit)\n\n        overall_loss = (loss_main + lambd3*loss_tit)/num_of_feedforwards  # becoz initially the summation is avg loss per mini batch(8) but we need avg loss per mini batch(24)\n        overall_loss.backward()\n        torch.nn.utils.clip_grad_norm_(mod.parameters(), 5)\n        optimizer.step()\n        \n        running_loss += overall_loss.item()\n        if(i%100 == 99):\n            loss_list.append({'epoch':epoch+1,'batch':i+1,'loss':round(running_loss / 100,3)})\n            print('[epoch : %d,batch : %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 100))\n            \n#             print('gradients : ')\n#             print('main_sci out :')\n#             print(list(mod.named_parameters())[-13][1].grad)\n#             print('main_pk out :')\n#             print(list(mod.named_parameters())[-9][1].grad)\n#             print('#'*50)\n            running_loss = 0.0\n   \n# validation ------------------------\n    with torch.no_grad():\n        mod.eval()\n        \n        # calculating f1_score for train data\n        for d in train_data:\n            x = d[0].to(device)\n            y = d[1].to(device)\n            for yt in y.cpu():\n                ytr.append(yt)\n            y_pred = mod(x,0,'pk')[0].cpu()\n            for yt in y_pred:\n                ypr.append(yt)\n                \n        f1 = f1_score(ytr,ypr,average='macro')\n        \n        # calculating f1_score for validation data\n        for d in val_data:\n            xv = d[0].to(device)\n            yv = d[1].to(device)\n            for yt in yv.cpu():\n                y_eval.append(yt)\n            y_pred = mod(xv,0,'pk')[0].cpu()\n            for yt in y_pred:\n                ypr_eval.append(yt)\n                \n        val_f1 = f1_score(y_eval,ypr_eval,average='macro')\n        \n        f1_list.append({'epoch':epoch+1,'train_f1_score':f1,'val_f1_score':val_f1})\n        \n    print('*'*40)\n    print('train confusion matrix : ')\n    print(confusion_matrix(ytr, ypr))\n    print('*'*40)\n    print('val confusion matrix : ')\n    print(confusion_matrix(y_eval, ypr_eval))\n    print('*'*40)\n    print('[epoch : %d] train_f1_macro: %.3f, val_f1_macro: %.3f' %(epoch+1, f1, val_f1))\n    print('*'*40)\n    if((epoch+1)%2==0):\n        torch.save(mod, f'./cohan_modelv3_scaffold4_pk_smote_ep{epoch+21}.pt')\n\nprint('Finished Training!!')            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom IPython.display import FileLinks\nos.chdir(r'../working')\nFileLinks('./')\n# for i in os.listdir('./'):\n#     if(i[:5]=='cohan'):\n#         FileLink(os.path.join(r'./',i))\n#         break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Exp - 0 Pride_Knoth Simple classifier**"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"pdtr['cited_title']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prtr = list(map(lambda t : t[:t.find('#AUTHOR_TAG')]+t[t.find('#AUTHOR_TAG')+11:],pdtr['citation_context']))\nyc = pdtr['citation_class_label'].values.tolist()\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\nx = list(map(lambda t : tokenizer.encode(t),prtr))\nx_cited = list(map(lambda t : tokenizer.encode(t[0],padding=True,pad_to_max_length=True,max_length=251-len(t[1]))[1:],zip(pdtr['cited_title'],x)))\nx = [x+y for x,y in zip(x,x_cited)]\ny = torch.tensor(yc)\nx = torch.tensor(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prtr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vx = x[2600:]\nvy = y[2600:]\nx=x[:2600]\ny=y[:2600]\nprint(x.shape)\nprint(vx.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(y).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_over = SMOTE(sampling_strategy={0:1447,1:600,2:600,3:600,4:600,5:600})\ntr_under = RandomUnderSampler(sampling_strategy={0:600,1:600,2:600,3:600,4:600,5:600})\nx_smote,y_smote = tr_over.fit_sample(x,y)\nx_smote,y_smote = tr_under.fit_sample(x_smote,y_smote)\nprint(Counter(y_smote))\n\nval_over = SMOTE(sampling_strategy={0:201,1:100,2:100,3:100,4:100,5:100},k_neighbors=3)\nval_under = RandomUnderSampler(sampling_strategy={0:100,1:100,2:100,3:100,4:100,5:100})\nvx_smote,vy_smote = val_over.fit_sample(vx,vy)\nvx_smote,vy_smote = val_under.fit_sample(vx_smote,vy_smote)\nprint(Counter(vy_smote))\n\nx_smote = torch.tensor(x_smote)\ny_smote = torch.tensor(y_smote)\nvx_smote = torch.tensor(vx_smote)\nvy_smote = torch.tensor(vy_smote)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batchsize = 4\nmain_tr = torch.utils.data.TensorDataset(x_smote, y_smote)\nmain_val = torch.utils.data.TensorDataset(vx_smote, vy_smote)\ntrain_sampler = torch.utils.data.RandomSampler(main_tr)\ntrain_data = torch.utils.data.DataLoader(main_tr, sampler=train_sampler, batch_size=batchsize)\nval_sampler = torch.utils.data.RandomSampler(main_val)\nval_data = torch.utils.data.DataLoader(main_val, sampler=val_sampler, batch_size=batchsize)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t[1].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class simple_model(nn.Module):\n    def __init__(self,batch_size):\n        super().__init__()\n        self.batch_size = batch_size\n        self.BertModel = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n        self.lstm = nn.LSTM(768,50,num_layers=1,bidirectional=True,batch_first=True)\n        self.att = attention(batch_size)\n        self.lin1 = nn.Linear(100,32)\n        self.relu = torch.nn.ReLU()\n        self.drop = nn.Dropout(p=0.3)\n#         self.lin2 = nn.Linear(64,32)\n        self.lin2 = nn.Linear(32,6)\n        \n    def forward(self,x):\n        xbert=self.BertModel(x)\n        lstm,_=self.lstm(xbert[0])\n        att_layer = self.att(lstm).view(self.batch_size,100)\n        x = self.drop(att_layer)\n        last_lin = self.lin1(x)\n        x = self.relu(last_lin) \n        x = self.lin2(x)\n        return (x,att_layer,last_lin)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model(inp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"for i,t in enumerate(train_data):\n    inp,out = t[0].to(device),t[1].to(device)\n    print(inp.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = simple_model(batchsize)\nmodel.to(device)\nloss = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adadelta(model.parameters(), lr = 0.01)\nloss_list = []\nf1_list = []\n\nfor epoch in range(5):\n    total_loss = 0\n    ypr=[]\n    ytr=[]\n    y_eval=[]\n    ypr_eval=[]\n    \n    model.train()\n    \n    for i,t in enumerate(train_data):\n        inp,out = t[0].to(device),t[1].to(device)\n        optimizer.zero_grad()\n        pred = model(inp)[0]\n        loss_batch = loss(pred,out)\n        loss_batch.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n        optimizer.step()\n        total_loss += (loss_batch*batchsize).item()\n        \n        if(i%100 == 99):\n            loss_list.append({'epoch':epoch+1,'batch':i+1,'loss':round(total_loss / 100,3)})\n            print('[epoch : %d,batch : %5d] loss: %.3f' %(epoch + 1, i + 1, total_loss / 100))\n            total_loss = 0.0\n            \n    with torch.no_grad():\n        model.eval()\n        \n        # calculating f1_score for train data\n        for d in train_data:\n            x = d[0].to(device)\n            y = d[1].to(device)\n            for yt in y.cpu():\n                ytr.append(yt)\n                \n            z = model(x)[0]\n            z = F.softmax(z,dim=1)\n            z = torch.argmax(z,dim=1)    \n            y_pred = z.cpu()\n            for yt in y_pred:\n                ypr.append(yt)\n                \n        f1 = f1_score(ytr,ypr,average='macro')\n        \n        # calculating f1_score for validation data\n        for d in val_data:\n            xv = d[0].to(device)\n            yv = d[1].to(device)\n            for yt in yv.cpu():\n                y_eval.append(yt)\n            \n            z = model(xv)[0]\n            z = F.softmax(z,dim=1)\n            z = torch.argmax(z,dim=1)    \n            y_pred = z.cpu()\n            for yt in y_pred:\n                ypr_eval.append(yt)\n                \n        val_f1 = f1_score(y_eval,ypr_eval,average='macro')  \n        f1_list.append({'epoch':epoch+1,'train_f1_score':f1,'val_f1_score':val_f1})\n    \n    target_names = ['class 0', 'class 1', 'class 2', 'class 3', 'class 4', 'class 5']\n    print('*'*40)\n    print('[epoch : %d] train_f1_macro: %.3f, val_f1_macro: %.3f' %(epoch+1, f1, val_f1))\n    print('*'*40)\n    print('train classification report : ')\n    print(classification_report(ytr, ypr, target_names=target_names))\n    print('*'*40)\n    print('test classification report : ')\n    print(classification_report(y_eval,ypr_eval, target_names=target_names))\n    print('*'*40)\n    if((epoch+1)%10==0):\n        torch.save(model, f'./simple_model_ep{epoch+1}.pt')\n\nprint('Finished Training!!') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model, './simple_model_ep30_ml250.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Submission file generation\n\nprtr = list(map(lambda t : t[:t.find('#AUTHOR_TAG')]+t[t.find('#AUTHOR_TAG')+11:],pdtr['citation_context']))\nyc = pdtr['citation_class_label'].values.tolist()\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\nx = list(map(lambda t : tokenizer.encode(t),prtr))\nx_cited = list(map(lambda t : tokenizer.encode(t[0],padding=True,pad_to_max_length=True,max_length=251-len(t[1]))[1:],zip(pdtr['cited_title'],x)))\nx = [x+y for x,y in zip(x,x_cited)]\ny = torch.tensor(yc)\nx = torch.tensor(x)\n\nprte = list(map(lambda t : t[:t.find('#AUTHOR_TAG')]+t[t.find('#AUTHOR_TAG')+11:],pdte['citation_context']))\n# prte = list(map(lambda t : t[0] + ' ' + t[1],zip(prte,pdte['cited_title'])))\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\ntx = list(map(lambda t : tokenizer.encode(t),prte))\ntx_cited = list(map(lambda t : tokenizer.encode(t[0],padding=True,pad_to_max_length=True,max_length=251-len(t[1]))[1:],zip(pdte['cited_title'],tx)))\ntx = [x+y for x,y in zip(tx,tx_cited)]\ntx = torch.tensor(tx)\nprint(tx[0])\nind = list(pdte['unique_id'])\n\npred = []\nwith torch.no_grad():\n    model.eval()\n    for i in range(0,len(tx),4):\n        l=[]\n        x = tx[i:i+4]\n        idx = ind[i:i+4]\n        x = x.to(device)\n        y_pr = model(x)[0].cpu()\n        y_pr = F.softmax(y_pr,dim=1)\n        y_pr = torch.argmax(y_pr,dim=1)\n        for j in range(len(x)):\n            l = [idx[j],y_pr[j].item()]\n            pred.append(l)\n        \ndf = pd.DataFrame(pred, columns = ['unique_id', 'citation_class_label']) \ndf.set_index('unique_id', inplace = True)\n\nprint(df)\ndf.to_csv('./submission.csv') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['citation_class_label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Exp - 1 Multi-Tasking Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# citance + cited title data prep\nprtr = list(map(lambda t : t[:t.find('#AUTHOR_TAG')]+t[t.find('#AUTHOR_TAG')+11:],pdtr['citation_context']))\nyc = pdtr['citation_class_label'].values.tolist()\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\nx1 = list(map(lambda t : tokenizer.encode(t),prtr))\nx1_cited = list(map(lambda t : tokenizer.encode(t[0],padding=True,pad_to_max_length=True,max_length=251-len(t[1]))[1:],zip(pdtr['cited_title'],x1)))\nx1 = [x+y for x,y in zip(x1,x1_cited)]\ny1 = torch.tensor(yc)\nx1 = torch.tensor(x1)\n\nprint('Oversampling and undersampling======')\n#Oversampling the minority classes by SMOTE\ntr_over = SMOTE(sampling_strategy={0:1648,1:600,2:600,3:600,4:600,5:600})\n#Undersampling the majority class\ntr_under = RandomUnderSampler(sampling_strategy={0:600,1:600,2:600,3:600,4:600,5:600})\nx1_smote,y1_smote = tr_over.fit_sample(x1,y1)\nx1_smote,y1_smote = tr_under.fit_sample(x1_smote,y1_smote)\nprint(Counter(y1_smote))\n\nx1_smote = torch.tensor(x1_smote)\ny1_smote = torch.tensor(y1_smote)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(y).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# citance + citing title data prep\nprtr = list(map(lambda t : t[:t.find('#AUTHOR_TAG')]+t[t.find('#AUTHOR_TAG')+11:],pdtr['citation_context']))\nx2 = list(map(lambda t : tokenizer.encode(t),prtr))\nx2_citing = list(map(lambda t : tokenizer.encode(t[0],padding=True,pad_to_max_length=True,max_length=251-len(t[1]))[1:],zip(pdtr['citing_title'],x2)))\nx2 = [x+y for x,y in zip(x2,x2_citing)]\nx2 = torch.tensor(x2)\ny2 = torch.tensor(yc)\nx1 = torch.tensor(x1)\n\nprint('Oversampling and undersampling======')\nx2_smote,y2_smote = tr_over.fit_sample(x2,y2)\nx2_smote,y2_smote = tr_under.fit_sample(x2_smote,y2_smote)\nprint(Counter(y2_smote))\n\nx2_smote = torch.tensor(x2_smote)\ny2_smote = torch.tensor(y2_smote)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(y1_smote == y2_smote).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# citation worthiness data prep\nx_cit = datac['cleaned_cite_text'].values.tolist()\n\nycit = datac['is_citation'].values.tolist()\nycit = list(map(lambda x : int(x),ycit))\n\n# removing instances with token size over 250\nxcit_idx_remove_250 = remove_idx(x_cit,250)\nfor i in sorted(xcit_idx_remove_250, reverse = True):  \n    del x_cit[i]\n    del ycit[i]\nprint(f'removed {len(xcit_idx_remove_250)} instances')\n\nxcit = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=250),x_cit))\n\nxcit,ycit = class_div(xcit,ycit,3600,2)\n\nxcit = torch.tensor(xcit)\nycit = torch.tensor(ycit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# main task data prep\nprtr = list(map(lambda t : t[:t.find('#AUTHOR_TAG')]+t[t.find('#AUTHOR_TAG')+11:],pdtr['citation_context']))\nyc = pdtr['citation_class_label'].values.tolist()\nx = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=250),prtr))\ny = torch.tensor(yc)\nx = torch.tensor(x)\n\nvx = x[2600:]\nvy = y[2600:]\nx=x[:2600]\ny=y[:2600]\nprint(x.shape)\nprint(vx.shape)\n\nprint('Oversampling and undersampling======')\ntr_over = SMOTE(sampling_strategy={0:1447,1:600,2:600,3:600,4:600,5:600})\ntr_under = RandomUnderSampler(sampling_strategy={0:600,1:600,2:600,3:600,4:600,5:600})\nx_smote,y_smote = tr_over.fit_sample(x,y)\nx_smote,y_smote = tr_under.fit_sample(x_smote,y_smote)\nprint(Counter(y_smote))\n\nval_over = SMOTE(sampling_strategy={0:201,1:100,2:100,3:100,4:100,5:100},k_neighbors=3)\nval_under = RandomUnderSampler(sampling_strategy={0:100,1:100,2:100,3:100,4:100,5:100})\nvx_smote,vy_smote = val_over.fit_sample(vx,vy)\nvx_smote,vy_smote = val_under.fit_sample(vx_smote,vy_smote)\nprint(Counter(vy_smote))\n\nx_smote = torch.tensor(x_smote)\ny_smote = torch.tensor(y_smote)\nvx_smote = torch.tensor(vx_smote)\nvy_smote = torch.tensor(vy_smote)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batchSize = 16\nnum_of_feedforwards = 4\nmain_tr = torch.utils.data.TensorDataset(x_smote, y_smote)\nmain_val = torch.utils.data.TensorDataset(vx_smote, vy_smote)\ncited_tr = torch.utils.data.TensorDataset(x1_smote,y1_smote)\nciting_tr = torch.utils.data.TensorDataset(x2_smote,y2_smote)\ncitwor_tr = torch.utils.data.TensorDataset(xcit,ycit)\n \ntrain_sampler = torch.utils.data.RandomSampler(main_tr)\ntrain_data = torch.utils.data.DataLoader(main_tr, sampler=train_sampler, batch_size=batchSize//num_of_feedforwards)\n\ncited_sampler = torch.utils.data.RandomSampler(cited_tr)\ncited_data = torch.utils.data.DataLoader(cited_tr, sampler=cited_sampler, batch_size=batchSize//num_of_feedforwards)\n\ncitwor_sampler = torch.utils.data.RandomSampler(citwor_tr)\ncitwor_data = torch.utils.data.DataLoader(citwor_tr, sampler=citwor_sampler, batch_size=batchSize//num_of_feedforwards)\n\nval_sampler = torch.utils.data.RandomSampler(main_val)\nval_data = torch.utils.data.DataLoader(main_val, sampler=val_sampler, batch_size=batchSize//num_of_feedforwards)\n\nciting_sampler = torch.utils.data.RandomSampler(citing_tr)\nciting_data = torch.utils.data.DataLoader(citing_tr, sampler=citing_sampler, batch_size=batchSize//num_of_feedforwards)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class attention(nn.Module):\n    def __init__(self,batch_size,hidden_size=50,max_len=250):\n        super().__init__()\n        k = torch.empty(batch_size,2*hidden_size,1)\n        self.w = torch.nn.init.xavier_uniform_(k).to(device)\n        self.hidden = hidden_size\n        self.max_len = max_len\n    def forward(self,x):\n        #e = torch.mm(x.view(-1,2*hidden_size),self.w).view(-1,max_len,1)\n        # x.shape = (batch_size,max_len,2*hidden_size), w.shape = (2*hidden_size,1)\n        # e.shape = (batch_size,max_len,1)\n        # later on also try with w.shape = (batch_size,2*hidden,1) ; use torch.bmm(x,w) in that case instead of above np.dot implementation\n        e = torch.bmm(x,self.w)/math.sqrt(self.hidden)\n        att_weights = F.softmax(e,dim=1) # attention weights shape = (batch_size,max_len,1)\n        out = torch.bmm(x.transpose(1,2),att_weights)\n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feed forward of main task\nclass feedforward1(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.drop = nn.Dropout(p=0.3)\n        self.lin = nn.Linear(100,32)\n        self.relu = torch.nn.ReLU()\n        self.out = nn.Linear(32,6)\n    def forward(self,x):\n        x = self.drop(x)\n        x = self.lin(x)\n        x = self.relu(x)\n        x = self.out(x)\n        return x ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feed forward of citation worthiness scaffold\nclass feedforward2(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.drop = nn.Dropout(p=0.3)\n        self.lin = nn.Linear(100,32)\n        self.relu = torch.nn.ReLU()\n        self.out = nn.Linear(32,2)\n    def forward(self,x):\n        x = self.drop(x)\n        x = self.lin(x)\n        x = self.relu(x)\n        x = self.out(x)\n        return x ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feed forward of citance+cited title scaffold\nclass feedforward3(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.drop = nn.Dropout(p=0.3)\n        self.lin = nn.Linear(100,32)\n        self.relu = torch.nn.ReLU()\n        self.out = nn.Linear(32,6)\n    def forward(self,x):\n        x = self.drop(x)\n        x = self.lin(x)\n        x = self.relu(x)\n        x = self.out(x)\n        return x ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feed forward of citance+citing scaffold\nclass feedforward4(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.drop = nn.Dropout(p=0.3)\n        self.lin = nn.Linear(100,32)\n        self.relu = torch.nn.ReLU()\n        self.out = nn.Linear(32,6)\n    def forward(self,x):\n        x = self.drop(x)\n        x = self.lin(x)\n        x = self.relu(x)\n        x = self.out(x)\n        return x ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MTL_model(nn.Module):\n    def __init__(self,batch_size):\n        super().__init__()\n        self.batch_size = batch_size\n        self.BertModel = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n        self.lstm = nn.LSTM(768,50,num_layers=1,bidirectional=True,batch_first=True)\n        self.att = attention(batch_size)\n        self.main = feedforward1()\n        self.citwor = feedforward2()\n        self.cited = feedforward3()\n        self.citing = feedforward4()\n        \n    def forward(self,x,n):\n        xbert=self.BertModel(x)\n        lstm,_=self.lstm(xbert[0])\n        z = self.att(lstm).view(self.batch_size,100)\n        if(n==1):\n            return self.main(z)\n        \n        elif(n==2):\n            return self.citwor(z)\n        \n        elif(n==3):\n            return self.cited(z)\n        elif(n==4):\n            return self.citing(z)\n        else:\n            #predicting == training done!!\n            z = self.main(z)\n            z = F.softmax(z,dim=1)\n            return torch.argmax(z,dim=1)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(batchSize,num_of_feedforwards,l1=0.1,l2=0.05,l3=0.05,mod=None):\n    torch.manual_seed(-1)\n    #training for models\n    if(mod==None):    \n        mod=MTL_model(batchSize//num_of_feedforwards)\n        mod.to(device)\n\n    lambd1 = l1   #lambd1 for citation worthiness scaffold\n    lambd2 = l2    #lambd2 for citance+cited title scaffold\n    lambd3 = l3    #lambd3 for citance+citing title scaffold\n\n    loss = torch.nn.CrossEntropyLoss()\n    optimizer = torch.optim.SGD(mod.parameters(), lr = 0.01)\n\n    loss_list = []\n    f1_list = []\n    acc_list=[]\n    for epoch in range(20):\n        running_loss = 0\n        ypr=[]\n        ytr=[]\n        y_eval=[]\n        ypr_eval=[]\n\n    # training--------------------\n        mod.train()\n        for i,data in enumerate(zip(train_data,citwor_data,cited_data,citing_data)):\n            m = data[0]\n            cw = data[1]\n            cted = data[2]\n            cting = data[3]\n\n            in_main,tar_main = m[0].to(device),m[1].to(device)\n            in_citwor,tar_citwor = cw[0].to(device),cw[1].to(device)\n            in_cited,tar_cited = cted[0].to(device),cted[1].to(device)\n            in_citing,tar_citing = cting[0].to(device),cting[1].to(device)\n\n            optimizer.zero_grad()\n\n            main = mod(in_main,1)\n            citwor = mod(in_citwor,2)\n            cited = mod(in_cited,3)\n            citing = mod(in_citing,4)\n\n            loss_main = loss(main,tar_main)\n            loss_citwor = loss(citwor,tar_citwor)\n            loss_cited = loss(cited,tar_cited)\n            loss_citing = loss(citing,tar_citing)\n\n            overall_loss = (loss_main + lambd1*loss_citwor + lambd2*loss_cited + lambd3*loss_citing)/num_of_feedforwards  # becoz initially the summation is avg loss per mini batch(8) but we need avg loss per mini batch(24)\n            overall_loss.backward()\n            torch.nn.utils.clip_grad_norm_(mod.parameters(), 1)\n            optimizer.step()\n\n            running_loss += overall_loss.item()\n            if(i%100 == 99):\n                loss_list.append({'epoch':epoch+1,'batch':i+1,'loss':round(running_loss / 100,3)})\n                print('[epoch : %d,batch : %5d] loss: %.4f' %(epoch + 1, i + 1, running_loss / 100))\n                running_loss = 0.0\n\n    # validation ------------------------\n        with torch.no_grad():\n            mod.eval()\n\n            # calculating f1_score for train data\n            for d in train_data:\n                x = d[0].to(device)\n                y = d[1].to(device)\n                for yt in y.cpu():\n                    ytr.append(yt)\n                y_pred = mod(x,0).cpu()\n                for yt in y_pred:\n                    ypr.append(yt)\n\n            f1 = f1_score(ytr,ypr,average='macro')\n            accuracy = accuracy_score(ytr,ypr)\n            # calculating f1_score for validation data\n            for d in val_data:\n                xv = d[0].to(device)\n                yv = d[1].to(device)\n                for yt in yv.cpu():\n                    y_eval.append(yt)\n                y_pred = mod(xv,0).cpu()\n                for yt in y_pred:\n                    ypr_eval.append(yt)\n\n            val_f1 = f1_score(y_eval,ypr_eval,average='macro')\n            val_accuracy = accuracy_score(y_eval,ypr_eval)\n            acc_list.append({'epoch':epoch+1,'accuracy':accuracy,'val_accuracy':val_accuracy})\n            f1_list.append({'epoch':epoch+1,'train_f1_score':f1,'val_f1_score':val_f1})\n\n        print('*'*40)\n        print('[epoch : %d] train_f1_macro: %.3f, val_f1_macro: %.3f, accuracy: %.3f, val_accuracy: %.3f' %(epoch+1, f1, val_f1, accuracy, val_accuracy))\n        print('*'*40)\n        print('train confusion matrix : ')\n        print(confusion_matrix(ytr, ypr))\n        print('*'*40)\n        print('val confusion matrix : ')\n        print(confusion_matrix(y_eval, ypr_eval))\n        print('*'*40)\n        print('*'*40)\n        if((epoch+1)%5==0):\n            torch.save(mod, f'./MTL_model_ep{epoch+1}.pt')\n\n    print('Finished Training!!')    \n    return (mod,loss_list,f1_list,acc_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparams = {\n    'l1': [0.1,0.05,0.2],\n    'l2': [0.1,0.05,0.2],\n    'l3': [0.1,0.05,0.2]\n}\ngs = GridSearchCV(train_model(batchSize,num_of_feedforwards), params, refit=False, scoring='f1', verbose=1, cv=5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model,loss_list,f1_list,acc_list = train_model(batchSize,num_of_feedforwards)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ep = [i['epoch'] for i in f1_list]\ntrain_f1 = [i['train_f1_score'] for i in f1_list]\nval_f1 = [i['val_f1_score'] for i in f1_list]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = [i['loss'] for i in loss_list]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(list(range(180)),loss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(ep,train_f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(ep,val_f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = torch.load('../input/mlt-model/MTL_model_ep15_ml250.pt')\nmodel.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ytr=[]\nypr=[]\nwith torch.no_grad():\n    model.eval()\n# calculating f1_score for train data\n    for d in val_data:\n        x = d[0].to(device)\n        y = d[1].to(device)\n        for yt in y.cpu():\n            ytr.append(yt)\n        y_pred = model(x,0).cpu()\n        for yt in y_pred:\n            ypr.append(yt)\nprint('acc : ',accuracy_score(ytr,ypr))\nprint('f1 : ',f1_score(ytr,ypr,average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Submission\nprte = list(map(lambda t : t[:t.find('#AUTHOR_TAG')]+t[t.find('#AUTHOR_TAG')+11:],pdte['citation_context']))\nyc = pdtr['citation_class_label'].values.tolist()[:1000]\nx = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=250),prte))\ny = torch.tensor(yc)\nx = torch.tensor(x)\n\nprint(x.shape)\n\nmain_te = torch.utils.data.TensorDataset(x, y)\ntest_data = torch.utils.data.DataLoader(main_te, batch_size=4)\n\nind = list(pdte['unique_id'])\n\npred=[]\nypr=[]\nwith torch.no_grad():\n    model.eval()\n    for d in test_data:\n        x = d[0].to(device) \n        y_pred = model(x,0).cpu()\n        for yt in y_pred:\n            ypr.append(yt)\n    for j in range(len(ypr)):\n        l = [ind[j],ypr[j].item()]\n        pred.append(l)\ndf = pd.DataFrame(pred, columns = ['unique_id', 'citation_class_label']) \ndf.set_index('unique_id', inplace = True)\n\nprint(df)\ndf.to_csv('./submission_MTL_model.csv') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['citation_class_label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ind","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Exp - 2 Representations Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"simp_model = torch.load('../input/simple-model/simple_model_ep30_ml250.pt')\nsimp_model.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cohan_mod = torch.load('../input/latest-model-300/full_model_v1_epoch7_ml300.pt')\ncohan_mod.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# code for combining citance and cited title to feed to simp_model\n\nprtr = list(map(lambda t : t[:t.find('#AUTHOR_TAG')]+t[t.find('#AUTHOR_TAG')+11:],pdtr['citation_context']))\nyc = pdtr['citation_class_label'].values.tolist()\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\nx = list(map(lambda t : tokenizer.encode(t),prtr))\nx_cited = list(map(lambda t : tokenizer.encode(t[0],padding=True,pad_to_max_length=True,max_length=251-len(t[1]))[1:],zip(pdtr['cited_title'],x)))\nx1 = [x+y for x,y in zip(x,x_cited)]\ny1 = torch.tensor(yc)\nx1 = torch.tensor(x1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# code to concatenate the (cohan prediction on 3c data) with (citance of 3c data)\n\nyc = pdtr['citation_class_label'].values.tolist()\nx = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=300),prtr))\ny = torch.tensor(yc)\nx = torch.tensor(x)\n\nbatchsize = 4\nmain_tr = torch.utils.data.TensorDataset(x,y)\ntrain_sampler = torch.utils.data.RandomSampler(main_tr)\ntrain_data = torch.utils.data.DataLoader(main_tr, sampler=train_sampler, batch_size=batchsize)\n\nx = list(map(lambda t : tokenizer.encode(t),prtr))\ny_cohan = []\nwith torch.no_grad():\n    cohan_mod.eval()\n    for d in train_data:\n        x_con = d[0].to(device)\n        y_con = cohan_mod(x_con,0,'sci')\n        for i in y_con.cpu():\n            y_cohan.append(str(i.item()))\nx2 = list(map(lambda t : tokenizer.encode(t[0],padding=True,pad_to_max_length=True,max_length=251-len(t[1]))[1:],zip(y_cohan,x)))\nx2 = [x+y for x,y in zip(x,x2)]\nx2 = torch.tensor(x2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vx1 = x1[2600:]\nx1=x1[:2600]\n\nvx2 = x2[2600:]\nx2=x2[:2600]\n\nvy = y[2600:]\ny=y[:2600]\n\nprint(x1.shape)\nprint(x2.shape)\nprint(vx1.shape)\nprint(vx2.shape)\nprint(vy.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_over = SMOTE(sampling_strategy={0:1447,1:600,2:600,3:600,4:600,5:600})\ntr_under = RandomUnderSampler(sampling_strategy={0:600,1:600,2:600,3:600,4:600,5:600})\nx1_smote,y_smote = tr_over.fit_sample(x1,y)\nx1_smote,y_smote = tr_under.fit_sample(x1_smote,y_smote)\n\nx2_smote,y_smote = tr_over.fit_sample(x2,y)\nx2_smote,y_smote = tr_under.fit_sample(x2_smote,y_smote)\nprint(Counter(y_smote))\n\nval1_over = SMOTE(sampling_strategy={0:201,1:100,2:100,3:100,4:100,5:100},k_neighbors=3)\nval1_under = RandomUnderSampler(sampling_strategy={0:100,1:100,2:100,3:100,4:100,5:100})\nvx1_smote,vy_smote = val1_over.fit_sample(vx1,vy)\nvx1_smote,vy_smote = val1_under.fit_sample(vx1_smote,vy_smote)\n\nvx2_smote,vy_smote = val1_over.fit_sample(vx2,vy)\nvx2_smote,vy_smote = val1_under.fit_sample(vx2_smote,vy_smote)\nprint(Counter(vy_smote))\n\nx1_smote = torch.tensor(x1_smote)\nx2_smote = torch.tensor(x2_smote)\ny_smote = torch.tensor(y_smote)\nvx1_smote = torch.tensor(vx1_smote)\nvx2_smote = torch.tensor(vx2_smote)\nvy_smote = torch.tensor(vy_smote)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batchsize = 4\nmain_tr1 = torch.utils.data.TensorDataset(x1_smote, y_smote)\nmain_val1 = torch.utils.data.TensorDataset(vx1_smote, vy_smote)\ntrain_sampler1 = torch.utils.data.RandomSampler(main_tr1)\ntrain_data1 = torch.utils.data.DataLoader(main_tr1, sampler=train_sampler1, batch_size=batchsize)\nval_sampler1 = torch.utils.data.RandomSampler(main_val1)\nval_data1 = torch.utils.data.DataLoader(main_val1, sampler=val_sampler1, batch_size=batchsize)\n\nmain_tr2 = torch.utils.data.TensorDataset(x2_smote, y_smote)\nmain_val2 = torch.utils.data.TensorDataset(vx2_smote, vy_smote)\ntrain_sampler2 = torch.utils.data.RandomSampler(main_tr2)\ntrain_data2 = torch.utils.data.DataLoader(main_tr2, sampler=train_sampler2, batch_size=batchsize)\nval_sampler2 = torch.utils.data.RandomSampler(main_val2)\nval_data2 = torch.utils.data.DataLoader(main_val2, sampler=val_sampler2, batch_size=batchsize)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class rep_model(nn.Module):\n    def __init__(self,batch_size):\n        super().__init__()\n        self.batch_size = batch_size\n        self.simple_model = simp_model\n        for param in self.simple_model.parameters():\n            param.requires_grad = False\n        self.BertModel = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n        self.lstm = nn.LSTM(768,50,num_layers=1,bidirectional=True,batch_first=True)\n        self.att = attention(batch_size)\n        self.relu = torch.nn.ReLU()\n        self.drop = nn.Dropout(p=0.3)\n        self.lin1 = nn.Linear(200,64)\n        self.lin2 = nn.Linear(64,32)\n        self.lin3 = nn.Linear(32,6)\n        \n    def forward(self,x1,x2):\n        rep1 = self.simple_model(x1)[1]\n        \n        xbert=self.BertModel(x2)\n        lstm,_=self.lstm(xbert[0])\n        rep2 = self.att(lstm).view(self.batch_size,100)\n        \n        final_rep = torch.cat((rep1,rep2),1).view(self.batch_size,-1)\n        \n        x = self.drop(final_rep)\n        x = self.lin1(x)\n        x = self.relu(x)\n        x = self.lin2(x)\n        x = self.relu(x)\n        x = self.lin3(x)\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i,t in enumerate(zip(train_data1,train_data2)):\n    data1 = t[0]\n    data2 = t[1]\n    x1 = data1[0]\n    x2 = data2[0]\n    y = data1[1]\n    print(x1.shape)\n    print(i)\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"x2[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = rep_model(batchsize)\nmodel.to(device)\nloss = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adadelta(model.parameters(), lr = 0.01)\nloss_list = []\nf1_list = []\nacc_list=[]\n\nfor epoch in range(25):\n    total_loss = 0\n    ypr=[]\n    ytr=[]\n    y_eval=[]\n    ypr_eval=[]\n    \n    model.train()\n    \n    for i,t in enumerate(zip(train_data1,train_data2)):\n        data1 = t[0]\n        data2 = t[1]\n        \n        x1 = data1[0].to(device)\n        x2 = data2[0].to(device)\n        y = data1[1].to(device)\n        \n        optimizer.zero_grad()\n        pred = model(x1,x2)\n        loss_batch = loss(pred,y)\n        loss_batch.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n        optimizer.step()\n        total_loss += (loss_batch).item()\n        \n        if(i%100 == 99):\n            loss_list.append({'epoch':epoch+1,'batch':i+1,'loss':round(total_loss / 100,3)})\n            print('[epoch : %d,batch : %5d] loss: %.3f' %(epoch + 1, i + 1, total_loss / 100))\n            total_loss = 0.0\n            \n    with torch.no_grad():\n        model.eval()\n        simp_model.eval()\n        \n        # calculating f1_score for train data\n        for d in zip(train_data1,train_data2):\n            x1 = d[0][0].to(device)\n            x2 = d[1][0].to(device)\n            y = d[0][1].to(device)\n            \n            for yt in y.cpu():\n                ytr.append(yt)\n                \n            z = model(x1,x2)\n            z = F.softmax(z,dim=1)\n            z = torch.argmax(z,dim=1)    \n            y_pred = z.cpu()\n            for yt in y_pred:\n                ypr.append(yt)\n                \n        f1 = f1_score(ytr,ypr,average='macro')\n        accuracy = accuracy_score(ytr,ypr)\n        \n        # calculating f1_score for validation data\n        for d in zip(val_data1,val_data2):\n            xv1 = d[0][0].to(device)\n            xv2 = d[1][0].to(device)\n            yv = d[0][1].to(device)\n            \n            for yt in yv.cpu():\n                y_eval.append(yt)\n            \n            z = model(xv1,xv2)\n            z = F.softmax(z,dim=1)\n            z = torch.argmax(z,dim=1)    \n            y_pred = z.cpu()\n            for yt in y_pred:\n                ypr_eval.append(yt)\n                \n        val_f1 = f1_score(y_eval,ypr_eval,average='macro')  \n        val_accuracy = accuracy_score(y_eval,ypr_eval)\n        acc_list.append({'epoch':epoch+1,'accuracy':accuracy,'val_accuracy':val_accuracy})\n        f1_list.append({'epoch':epoch+1,'train_f1_score':f1,'val_f1_score':val_f1})\n    \n    target_names = ['class 0', 'class 1', 'class 2', 'class 3', 'class 4', 'class 5']\n    print('*'*40)\n    print('[epoch : %d] train_f1_macro: %.3f, val_f1_macro: %.3f, accuracy: %.3f, val_accuracy: %.3f' %(epoch+1, f1, val_f1, accuracy, val_accuracy))\n    print('*'*40)\n    print('train confusion matrix : ')\n    print(confusion_matrix(ytr, ypr))\n    print('*'*40)\n    print('val confusion matrix : ')\n    print(confusion_matrix(y_eval, ypr_eval))\n    print('*'*40)\n    print('train classification report : ')\n    print(classification_report(ytr, ypr, target_names=target_names))\n    print('*'*40)\n    print('test classification report : ')\n    print(classification_report(y_eval,ypr_eval, target_names=target_names))\n    print('*'*40)\n    if((epoch+1)%5==0):\n        torch.save(model, f'./simple_model_ep{epoch+1}.pt')\n\nprint('Finished Training!!') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.size(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.size(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = torch.load('./simple_model_ep15.pt')\nmodel.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Submission file generation\n\nbatchsize = 4\nprte = list(map(lambda t : t[:t.find('#AUTHOR_TAG')]+t[t.find('#AUTHOR_TAG')+11:],pdte['citation_context']))\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\ntx1 = list(map(lambda t : tokenizer.encode(t),prte))\ntx1_cited = list(map(lambda t : tokenizer.encode(t[0],padding=True,pad_to_max_length=True,max_length=251-len(t[1]))[1:],zip(pdte['cited_title'],tx1)))\ntx1 = [x+y for x,y in zip(tx1,tx1_cited)]\ntx1 = torch.tensor(tx1)\nprint(tx1[0])\n\n# code to concatenate the (cohan prediction on 3c data) with (citance of 3c data)\n\nyc = pdtr['citation_class_label'].values.tolist()[:1000]   # any random value of y taken so that we can use the TensorDataset for ease in coding\nx = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=300),prte))\ny = torch.tensor(yc)\nx = torch.tensor(x)\n\nbatchsize = 4\nmain_te = torch.utils.data.TensorDataset(x,y)\ntest_sampler = torch.utils.data.RandomSampler(main_te)\ntest_data = torch.utils.data.DataLoader(main_te, sampler=test_sampler, batch_size=batchsize)\n\nx = list(map(lambda t : tokenizer.encode(t),prte))\ny_cohan = []\nwith torch.no_grad():\n    cohan_mod.eval()\n    for d in test_data:\n        x_con = d[0].to(device)\n        y_con = cohan_mod(x_con,0,'sci')\n        for i in y_con.cpu():\n            y_cohan.append(str(i.item()))\nx2 = list(map(lambda t : tokenizer.encode(t[0],padding=True,pad_to_max_length=True,max_length=251-len(t[1]))[1:],zip(y_cohan,x)))\ntx2 = [x+y for x,y in zip(x,x2)]\ntx2 = torch.tensor(tx2)\nprint('tx2 shape : ',tx2.shape)\n\nind = list(pdte['unique_id'])\n\npred = []\nwith torch.no_grad():\n    model.eval()\n    for i in range(0,len(tx1),4):\n        l=[]\n        x1 = tx1[i:i+4]\n        x2 = tx2[i:i+4]\n        idx = ind[i:i+4]\n        x1 = x1.to(device)\n        x2 = x2.to(device)\n        y_pr = model(x1,x2).cpu()\n        y_pr = F.softmax(y_pr,dim=1)\n        y_pr = torch.argmax(y_pr,dim=1)\n        for j in range(len(x1)):\n            l = [idx[j],y_pr[j].item()]\n            pred.append(l)\n        \ndf = pd.DataFrame(pred, columns = ['unique_id', 'citation_class_label']) \ndf.set_index('unique_id', inplace = True)\n\nprint(df)\ndf.to_csv('./submission.csv') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['citation_class_label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Exp - 3 Late fusion**"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"mod = torch.load('../input/cohanmodel-on-sci-and-acl/full_model_ep25.pt')\nmod.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = torch.load('./model_pk_epoch20.pt')\nmodel.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prtr = list(map(lambda t : t[:t.find('#AUTHOR_TAG')]+'( @@CITATION )'+t[t.find('#AUTHOR_TAG')+11:],pdtr['citation_context']))\nyc = pdtr['citation_class_label'].values.tolist()\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\nx = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=300),prtr))\ny = torch.tensor(yc)\nx = torch.tensor(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\nacl_tr = list(acl_pdm['cleaned_cite_text'])\nacl_y = acl_pdm['intent'].values.tolist()\nacl_label={'Background':0,'CompareOrContrast':1,'Extends':2,'Future':3,'Motivation':4,'Uses':5}\nacl_y = list(map(lambda t : acl_label[t],acl_y))\n\nprint(acl_y[:5])\n\nacl_tr_idx_remove_300 = remove_idx(acl_tr,300)\nfor i in sorted(acl_tr_idx_remove_300, reverse = True):  \n    del acl_tr[i]\n    del acl_y[i]\nprint(f'removed {len(acl_tr_idx_remove_300)} instances')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\nacl_x = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=300),acl_tr))\nacl_y = torch.tensor(acl_y)\nacl_x = torch.tensor(acl_x)\nprint(acl_x[:5])\nprint(acl_x.shape)\nprint(acl_y[:5])\nprint(acl_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_tr = torch.cat((x,acl_x),0)\ny_tr = torch.cat((y,acl_y),0)\nprint(x_tr.shape)\nprint(y_tr.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx,vx,y,vy = train_test_split(x, y, test_size=400/3000, random_state=42,shuffle=True)\nprint(x.shape)\nprint(vx.shape)\nprint(y.shape)\nprint(vy.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(y).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Series(vy).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yall = [i.item() for i in y]\nCounter(yall)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yallv = [i.item() for i in vy]\nCounter(yallv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# only oversampling of minority classes done for now!!!\nsampling_strategy = {0:2126,1:600,2:600,3:600,4:600,5:600}  # use this if u wnat to undersample using RandomUnderSampler after oversampling by SMOTE\ntr_over = SMOTE(sampling_strategy='not majority')\n#tr_under = RandomUnderSampler(sampling_strategy={0:600,1:600,2:600,3:600,4:600,5:600})\nx_smote,y_smote = tr_over.fit_sample(x,y)\n#x_smote,y_smote = tr_under.fit_sample(x_smote,y_smote)\nCounter(y_smote)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sampling_strategy = {0:201,1:100,2:100,3:100,4:100,5:100} # use this if u want to undersample as well after oversampling by SMOTE is done\n# while using above dict for sampling strategy of SMOTE, put k_neighbors = 3\nval_over = SMOTE(sampling_strategy='not majority')\n#val_under = RandomUnderSampler(sampling_strategy={0:100,1:100,2:100,3:100,4:100,5:100})\nvx_smote,vy_smote = val_over.fit_sample(vx,vy)\n#vx_smote,vy_smote = val_under.fit_sample(vx_smote,vy_smote)\nCounter(vy_smote)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_smote = torch.tensor(x_smote)\ny_smote = torch.tensor(y_smote)\nvx_smote = torch.tensor(vx_smote)\nvy_smote = torch.tensor(vy_smote)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_smote.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vy_smote.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to maintain every batch with batch_size = 4 => we leave the last 2 instances...........\n# vy_smote = vy_smote[:-2]\n# vx_smote = vx_smote[:-2]\n# print(vy_smote.shape)\n\nbatchsize = 4\nmain_tr = torch.utils.data.TensorDataset(x_smote, y_smote)\nmain_val = torch.utils.data.TensorDataset(vx_smote, vy_smote)\ntrain_sampler = torch.utils.data.RandomSampler(main_tr)\ntrain_data = torch.utils.data.DataLoader(main_tr, sampler=train_sampler, batch_size=batchsize)\nval_sampler = torch.utils.data.RandomSampler(main_val)\nval_data = torch.utils.data.DataLoader(main_val, sampler=val_sampler, batch_size=batchsize)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir('./glove')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from gensim.scripts.glove2word2vec import glove2word2vec\nglove_input_file = '../input/glove-pretrained/glove.6B.100d.txt'\nword2vec_output_file = './glove/glove.6B.100d.txt.word2vec'\nglove2word2vec(glove_input_file, word2vec_output_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from gensim.models import KeyedVectors\n# load the Stanford GloVe model\nfilename = './glove/glove.6B.100d.txt.word2vec'\nglove = KeyedVectors.load_word2vec_format(filename, binary=False)\nprint(glove)\n# # calculate: (king - man) + woman = ?\n# result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n# print(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"required_vocab = ['introduction','conclusion','experiments','method','related','work','true','false','background','result']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first=0\nembedding_matrix = dict()\nfor i in required_vocab:\n    if i=='related' or i=='work':\n        if(first):\n            second = i\n            if(first=='related'):\n                string = first + ' ' + second\n            else:\n                string = second + ' ' + first\n            embedding_matrix[string] = (glove[first]+glove[second])/2\n        else:    \n            first = i\n    else:\n        embedding_matrix[i]=glove[i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'introduction':0,'related work':1,'method':2,'experiments':3,'conclusion':4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_dict = {0:'background',1:'method',2:'result'}\nsec_label_dict = {0:'introduction',1:'related work',2:'method',3:'experiments',4:'conclusion'} \ncit_label_dict = {0:'false',1:'true'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sec_label_dict[3.]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# external knowledge (predictions of label,citation worthiness,section of citation) from pre trained cohan model for simple fusion model\n\nycit=[]\nysec=[]\nypredict=[]\nycitv=[]\nysecv=[]\nypredictv=[]\nwith torch.no_grad():\n    mod.eval()\n    for t in train_data:                       # pride knoth data\n        xt = t[0].to(device)\n        y_pred = mod(xt,0,'sci').cpu()\n        y_sec = torch.argmax(F.softmax(mod(xt,2),dim=1),dim=1).cpu()\n        y_cit_wor = torch.argmax(F.softmax(mod(xt,3),dim=1),dim=1).cpu()\n        for ypr,ys,yc in zip(y_pred,y_sec,y_cit_wor):\n            label = label_dict[ypr.item()]\n            sec_label=sec_label_dict[ys.item()]\n            cit_label=cit_label_dict[yc.item()]\n            ypredict.append(label)\n            ysec.append(sec_label)\n            ycit.append(cit_label)\n# ypredict = torch.tensor(ypredict).view(2600,1,-1).float().cuda()\n# ysec = torch.tensor(ysec).view(2600,1,-1).float().cuda()\n# ycit = torch.tensor(ycit).view(2600,1,-1).float().cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# external knowledge (last dense layer representation) from pre trained cohan model for simple fusion model\n\nypredict=[]\nypredictv=[]\nwith torch.no_grad():\n    mod.eval()\n    for t in train_data:                       # pride knoth data\n        xt = t[0].to(device)\n        y_pred = mod(xt,0,'pk')[4].cpu()\n        for ypr in y_pred:\n            ypredict.append(ypr.view(1,20,-1))\n    for t in val_data:                       # pride knoth data\n        xt = t[0].to(device)\n        y_pred = mod(xt,0,'pk')[4].cpu()\n        for ypr in y_pred:\n            ypredictv.append(ypr.view(1,20,-1))\nypredict = torch.cat(ypredict,0).cuda()\nypredictv = torch.cat(ypredictv,0).cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"ypredict.view(-1).cpu() \nyall=pd.Series(list(ypredict.view(-1).cpu()))\nyall.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ysec=pd.Series(ysec)\nysec.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ycit=pd.Series(ycit)\nycit.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# external knowledge from pre trained cohan model for conv layered fusion model\nycit=[]\nysec=[]\nypredict=[]\nycitv=[]\nysecv=[]\nypredictv=[]\n\ntrain_num = y_smote.shape[0]\nval_num = vy_smote.shape[0]\nwith torch.no_grad():\n    mod.eval()\n    for t in train_data:                       # pride knoth data\n        xt = t[0].to(device)\n        y_pred = mod(xt,0,'sci').cpu()\n        y_sec = torch.argmax(F.softmax(mod(xt,2),dim=1),dim=1).cpu()\n        y_cit_wor = torch.argmax(F.softmax(mod(xt,3),dim=1),dim=1).cpu()\n        for ypr,ys,yc in zip(y_pred,y_sec,y_cit_wor):\n            label = label_dict[ypr.item()]\n            sec_label=sec_label_dict[ys.item()]\n            cit_label=cit_label_dict[yc.item()]\n            \n            ypr_embed = embedding_matrix[label]\n            ys_embed = embedding_matrix[sec_label]\n            yc_embed = embedding_matrix[cit_label]\n            ypredict.append(ypr_embed)\n            ysec.append(ys_embed)\n            ycit.append(yc_embed)\n            \n    for t in val_data:    \n        xv = t[0].to(device)    \n        y_predv = mod(xv,0,'sci').cpu()\n        y_secv = torch.argmax(F.softmax(mod(xv,2),dim=1),dim=1).cpu()\n        y_cit_worv = torch.argmax(F.softmax(mod(xv,3),dim=1),dim=1).cpu()\n        for ypr,ys,yc in zip(y_predv,y_secv,y_cit_worv):\n            label = label_dict[ypr.item()]\n            sec_label=sec_label_dict[ys.item()]\n            cit_label=cit_label_dict[yc.item()]\n            \n            ypr_embed = embedding_matrix[label]\n            ys_embed = embedding_matrix[sec_label]\n            yc_embed = embedding_matrix[cit_label]\n            ypredictv.append(ypr_embed)\n            ysecv.append(ys_embed)\n            ycitv.append(yc_embed)\n            \nypredict = torch.tensor(ypredict).view(train_num,100,-1).float().cuda()\nysec = torch.tensor(ysec).view(train_num,100,-1).float().cuda()\nycit = torch.tensor(ycit).view(train_num,100,-1).float().cuda()\n\nypredictv = torch.tensor(ypredictv).view(val_num,100,-1).float().cuda()\nysecv = torch.tensor(ysecv).view(val_num,100,-1).float().cuda()\nycitv = torch.tensor(ycitv).view(val_num,100,-1).float().cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ypredictv.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"ysec[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y1=ypredict[:4]\ny2=ysec[:4]\ny3=ycit[:4]\ncat = torch.cat((y1,y2,y3),2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yel.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yel = torch.rand(4,100,1).cuda()\ncate = torch.cat((yel,cat),2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cate.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"for i in ysec:\n    print(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"yprel = torch.rand(4,1,1)\nysect = torch.rand(4,1,1)\nyw = torch.rand(4,1,1)\nyel = torch.rand(4,100,1)\nprint(ysect)\nprint(yw)\nprint(yprel)\nprint(yel)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat = torch.cat((yel,yprel,ysect,yw),1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Modelfusion(nn.Module):\n    def __init__(self,batch_size,fus):\n        super().__init__()\n        self.batch_size = batch_size\n        self.fus = fus                    # no. of different params(like pred. label,section,cit worthiness by pre trained cohan model) we are fusing with the output after attention layer.\n        self.n = 100 + fus\n        self.BertModel = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n        self.lstm = nn.LSTM(768,50,num_layers=1,bidirectional=True,batch_first=True)\n        self.att = attention(batch_size)\n        self.lin1 = nn.Linear(self.n,64)\n        self.relu = torch.nn.ReLU()\n        self.drop = nn.Dropout(p=0.4)\n        self.lin2 = nn.Linear(64,6)\n        \n    def forward(self,x,xfus):\n        xbert=self.BertModel(x)\n        lstm,_=self.lstm(xbert[0])\n        z = self.att(lstm)\n        z = torch.cat((z,xfus),1).view(self.batch_size,self.n)\n        z = self.drop(z)\n        z = self.lin1(z)\n        z = self.relu(z)\n        z = self.lin2(z)\n        return z","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# just for checking iutput dimensions\nfor i in train_data:\n    xall = i[0]\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# just for checking iutput dimensions\nxall[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# just for checking iutput dimensions\nbert = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")(xall[0].view(1,-1))\nlst,_ = nn.LSTM(768,50,num_layers=1,bidirectional=True,batch_first=True)(bert[0])\nat = attention(1)(lst.to(device))\nat.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# just for checking iutput dimensions\nxf = torch.rand(1,20,1).cuda()\ntorch.cat((at,xf),1).view(1,120).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Modelfusion_embed(nn.Module):\n    def __init__(self,batch_size,fus):\n        super().__init__()\n        self.batch_size = batch_size\n        self.fus = fus                    # no. of different params(like pred. label,section,cit worthiness by pre trained cohan model) we are fusing with the output after attention layer.\n        self.n = 100 + fus\n        self.BertModel = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\")\n        self.lstm = nn.LSTM(768,50,num_layers=1,bidirectional=True,batch_first=True)\n        self.att = attention(batch_size)\n        self.cnn1 = nn.Conv1d(4,2,2,stride=2)\n        self.max = nn.MaxPool1d(2, stride=2)\n        self.lin1 = nn.Linear(50,16)\n        self.relu = torch.nn.ReLU()\n        self.drop = nn.Dropout(p=0.4)\n        self.lin2 = nn.Linear(16,6)\n        \n    def forward(self,x,xfus):\n        xbert=self.BertModel(x)\n        lstm,_=self.lstm(xbert[0])\n        z = self.att(lstm)\n        z = torch.cat((z,xfus),2).permute(0,2,1)\n        z = self.cnn1(z)\n        z = self.relu(z)\n        z = self.max(z)\n        z = self.lin1(z.view(self.batch_size,-1))\n        z = self.relu(z)\n        z = self.drop(z)\n        z = self.lin2(z)\n        return z","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = nn.Conv1d(4, 2, 2, stride=2)\nmx = nn.MaxPool1d(2, stride=2)\ninput = torch.randn(4, 4, 100)\noutput = m(input)\nprint(output.shape)\noutput = mx(output)\nprint(output.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir('./models')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fus.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluation of model before training...........\n\nmodel = Modelfusion_embed(batchsize,3)\nmodel.to(device)\nypr=[]\nytr=[]\ny_eval=[]\nypr_eval=[]\nwith torch.no_grad():\n    model.eval()\n        \n    # calculating f1_score for train data\n    for i,t in enumerate(train_data):\n        x = t[0].to(device)\n        y = t[1].to(device)\n        for yt in y.cpu():\n            ytr.append(yt)\n                \n        y1 = ypredict[i*batchsize:(i+1)*batchsize]\n        y2 = ysec[i*batchsize:(i+1)*batchsize]\n        y3 = ycit[i*batchsize:(i+1)*batchsize]\n        fus = torch.cat((y1,y2,y3),2)    \n        z = model(x,fus)\n        z = F.softmax(z,dim=1)\n        z = torch.argmax(z,dim=1)    \n        y_pred = z.cpu()\n        for yt in y_pred:\n            ypr.append(yt)\n                \n    f1 = f1_score(ytr,ypr,average='macro')\n    for i,t in enumerate(val_data):\n        xv = t[0].to(device)\n        yv = t[1].to(device)\n        for yt in yv.cpu():\n            y_eval.append(yt)\n            \n        y1 = ypredictv[i*batchsize:(i+1)*batchsize]\n        y2 = ysecv[i*batchsize:(i+1)*batchsize]\n        y3 = ycitv[i*batchsize:(i+1)*batchsize]\n        fus = torch.cat((y1,y2,y3),2) \n        z = model(xv,fus)\n        z = F.softmax(z,dim=1)\n        z = torch.argmax(z,dim=1)    \n        y_pred = z.cpu()\n        for yt in y_pred:\n            ypr_eval.append(yt)\n                \n    val_f1 = f1_score(y_eval,ypr_eval,average='macro')  \nprint('train_f1 score before training : ',f1)\nprint('val_f1 score before training : ',val_f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ytr1 = [i.item() for i in ytr]\npd.Series(ytr1).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_eval1 = [i.item() for i in y_eval]\npd.Series(y_eval1).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(ytr1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ypr1 = [i.item() for i in ypr]\npd.Series(ypr1).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ypredict.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = torch.load('./acl_fusionmodel_ep15.pt')\nmodel.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for param in model.parameters():\n  print(param.name,param.data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name, param in model.named_parameters():\n    if(name.split('.')[0]!='BertModel'):\n        print(name,param.data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"print('gradients of fusion model before training : ')\nfor name,params in model.named_parameters():\n    print(name)\n    print(params.grad)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training of the model\n\n# model = Modelfusion(batchsize,20)\n# model.to(device)\n# loss = torch.nn.CrossEntropyLoss()\n# optimizer = torch.optim.Adadelta(model.parameters(), lr = 0.01)\n\n# loss_list = []\n# f1_list = []\n# acc_list=[]\n\n# print('weights before the start of training : ')\n# for name, param in model.named_parameters():\n#     if(name.split('.')[0]!='BertModel'):\n#         print(name,param.data)\n        \nprint('gradients of fusion model last layer before training : ')\nprint(list(model.named_parameters())[-1][0])\nprint(list(model.named_parameters())[-1][1].grad)\nprint(list(model.named_parameters())[-2][0])\nprint(list(model.named_parameters())[-2][1].grad)\nprint('*'*80)\n\nfor epoch in range(5):\n    total_loss = 0\n    ypr=[]\n    ytr=[]\n    y_eval=[]\n    ypr_eval=[]\n    \n    model.train()\n    \n    print(f'gradients of fusion model before epoch {epoch+1} : ')\n    for name,params in model.named_parameters():\n        print(name)\n        print(params.grad)\n        \n    print('@'*80)\n    \n    \n    for i,t in enumerate(train_data):\n        inp,out = t[0].to(device),t[1].to(device)\n        \n        optimizer.zero_grad()\n        \n        y1 = ypredict[i*batchsize:(i+1)*batchsize]\n#         y2 = ysec[i*batchsize:(i+1)*batchsize]\n#         y3 = ycit[i*batchsize:(i+1)*batchsize]\n       # fus = torch.cat((y1,y2,y3),2) \n        fus = y1\n        \n        pred = model(inp,fus)\n        \n        loss_batch = loss(pred,out)\n        \n        loss_batch.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n        optimizer.step()\n        total_loss += loss_batch.item()\n        \n        if(i%100 == 99):\n            loss_list.append({'epoch':epoch+1,'batch':i+1,'loss':round(total_loss / 100,3)})\n            print('[epoch : %d,batch : %5d] loss: %.3f' %(epoch + 1, i + 1, total_loss / 100))\n            total_loss = 0.0\n            print('\\n')\n            print('grads of last layer of fusion model: ')\n            print(list(model.named_parameters())[-1][1].grad)\n            print('@'*80)\n            \n    with torch.no_grad():\n        model.eval()\n        \n        # calculating f1_score for train data\n        for i,t in enumerate(train_data):\n            x = t[0].to(device)\n            y = t[1].to(device)\n            for yt in y.cpu():\n                ytr.append(yt)\n                \n            y1 = ypredict[i*batchsize:(i+1)*batchsize]\n#             y2 = ysec[i*batchsize:(i+1)*batchsize]\n#             y3 = ycit[i*batchsize:(i+1)*batchsize]\n#             fus = torch.cat((y1,y2,y3),2) \n            fus = y1\n            z = model(x,fus)\n            z = F.softmax(z,dim=1)\n            z = torch.argmax(z,dim=1)    \n            y_pred = z.cpu()\n            for yt in y_pred:\n                ypr.append(yt)\n                \n        f1 = f1_score(ytr,ypr,average='macro')\n        accuracy = accuracy_score(ytr,ypr)\n        \n        # calculating f1_score for validation data\n        for i,t in enumerate(val_data):\n            xv = t[0].to(device)\n            yv = t[1].to(device)\n            for yt in yv.cpu():\n                y_eval.append(yt)\n            \n            y1 = ypredictv[i*batchsize:(i+1)*batchsize]\n#             y2 = ysecv[i*batchsize:(i+1)*batchsize]\n#             y3 = ycitv[i*batchsize:(i+1)*batchsize]\n#             fus = torch.cat((y1,y2,y3),2) \n            fus =y1\n            z = model(xv,fus)\n            z = F.softmax(z,dim=1)\n            z = torch.argmax(z,dim=1)    \n            y_pred = z.cpu()\n            for yt in y_pred:\n                ypr_eval.append(yt)\n                \n        val_f1 = f1_score(y_eval,ypr_eval,average='macro')  \n        val_accuracy = accuracy_score(y_eval,ypr_eval)\n        acc_list.append({'epoch':epoch+1,'accuracy':accuracy,'val_accuracy':val_accuracy})\n        f1_list.append({'epoch':epoch+1,'train_f1_score':f1,'val_f1_score':val_f1})\n    \n    print('*'*40)\n    print('[epoch : %d] train_f1_macro: %.3f, val_f1_macro: %.3f,  accuracy: %.3f, val_accuracy: %.3f' %(epoch+1, f1, val_f1, accuracy, val_accuracy))\n    print('train confusion matrix : ')\n    print(confusion_matrix(ytr, ypr))\n    print('*'*40)\n    print('val confusion matrix : ')\n    print(confusion_matrix(y_eval, ypr_eval))\n    print('#'*80)\n    \n    if((epoch+1)%2==0):\n        print('weights of the non-Bert layers for epoch {epoch+1} : ')\n        for name, param in model.named_parameters():\n            if(name.split('.')[0]!='BertModel'):\n                print(name,param.data)\n        print('#'*80)\n            \n    if((epoch+1)%5==0):\n        torch.save(model, f'./acl_fusionmodel_ep{epoch+1}.pt')\n\nprint('Finished Training!!') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('weights of fusion model before the start of training : ')\nfor name, param in model.named_parameters():\n    if(name.split('.')[0]!='BertModel'):\n        print(name,param.data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'gradients of cohan model aftre training : ')\nfor name,params in mod.named_parameters():\n    print(name)\n    print(params.grad)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'gradients of fusion model aftre training : ')\nfor name,params in model.named_parameters():\n    print(name)\n    print(params.grad)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(list(model.named_parameters())[-1][1].grad)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(model.parameters())[-1].grad","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ep = [i['epoch'] for i in f1_list]\ntrain_f1 = [i['train_f1_score'] for i in f1_list]\nval_f1 = [i['val_f1_score'] for i in f1_list]\n\nloss_graph = [i['loss'] for i in loss_list]\n\nimport matplotlib.pyplot as plt\nplt.plot(ep,train_f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(ep,val_f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(list(range(315)),loss_graph)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model, f'./acl_fusionmodel_ep15_diff.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.chdir(r'../working')\nfrom IPython.display import FileLink\nFileLink(r'./acl_fusionmodel_ep20.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"for param in mod.parameters():\n  print(param)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#before training\nfor param in model.parameters():\n  print(param)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#after training\nfor param in model.parameters():\n  print(param)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ypr1 = [i.item() for i in ypr]\npd.Series(ypr1).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model,'./model_pk_epoch24.pt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Submission file generation for last layer representation variant using (ACL + 3C) data \n\nprte = list(map(lambda t : t[:t.find('#AUTHOR_TAG')]+'( @@CITATION )'+t[t.find('#AUTHOR_TAG')+11:],pdte['citation_context']))\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\ntx = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=300),prte))\ntx = torch.tensor(tx)\n\nind = list(pdte['unique_id'])\n\npred = []\nwith torch.no_grad():\n    model.eval()\n    mod.eval()\n    for i in range(0,len(tx),4):\n        l=[]\n        ypredict=[]\n        x = tx[i:i+4]\n        x = x.to(device)\n        if(i==0):\n            print(x.shape)\n        y_pred = mod(x,0,'sci')[1].cuda()\n        \n        for ypr in y_pred:\n            ypredict.append(ypr.view(1,20,-1))\n        \n        ypredict = torch.cat(ypredict,0)\n        idx = ind[i:i+4]\n        fus = ypredict\n        if(i==0):\n            print(ypredict.shape)\n        \n        y_pr = model(x,fus)\n        y_pr = F.softmax(y_pr,dim=1)\n        if(i==0):\n            print(y_pr)\n        y_pr = torch.argmax(y_pr,dim=1).cpu()\n        \n        if(i==0):\n            print(y_pr)\n            \n        for j in range(len(x)):\n            l = [idx[j],y_pr[j].item()]\n            pred.append(l)\n            \ndf = pd.DataFrame(pred, columns = ['unique_id', 'citation_class_label']) \ndf.set_index('unique_id', inplace = True)\n\nprint(df)\ndf.to_csv('./submission4.csv') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Submission file generation for conv layer variant\n\nprte = list(map(lambda t : t[:t.find('#AUTHOR_TAG')]+t[t.find('#AUTHOR_TAG')+11:],pdte['citation_context']))\ntokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\",do_lower_case=True)\ntx = list(map(lambda t : tokenizer.encode(t,padding=True,pad_to_max_length=True,max_length=300),prte))\ntx = torch.tensor(tx)\n\nind = list(pdte['unique_id'])\n\npred = []\nwith torch.no_grad():\n    model.eval()\n    mod.eval()\n    for i in range(0,len(tx),4):\n        l=[]\n        ypredict=[]\n        ysec=[]\n        ycit=[]\n        x = tx[i:i+4]\n        x = x.to(device)\n        if(i==0):\n            print(x.shape)\n        y_pred = mod(x,0,'sci').view(4,1,-1).float().cuda()\n        y_sec = torch.argmax(F.softmax(mod(x,2),dim=1),dim=1).view(4,1,-1).float().cuda()\n        y_cit_wor = torch.argmax(F.softmax(mod(x,3),dim=1),dim=1).view(4,1,-1).float().cuda()\n        \n        for ypr,ys,yc in zip(y_pred,y_sec,y_cit_wor):\n            label = label_dict[ypr.item()]\n            sec_label=sec_label_dict[ys.item()]\n            cit_label=cit_label_dict[yc.item()]\n            \n            ypr_embed = embedding_matrix[label]\n            ys_embed = embedding_matrix[sec_label]\n            yc_embed = embedding_matrix[cit_label]\n            ypredict.append(ypr_embed)\n            ysec.append(ys_embed)\n            ycit.append(yc_embed)\n        ypredict = torch.tensor(ypredict).view(4,100,-1).float().cuda()\n        ysec = torch.tensor(ysec).view(4,100,-1).float().cuda()\n        ycit = torch.tensor(ycit).view(4,100,-1).float().cuda()\n        idx = ind[i:i+4]\n        fus = torch.cat((ypredict,ysec,ycit),2)\n        if(i==0):\n            print(ypredict.shape)\n            print(ysec.shape)\n            print(ycit.shape)\n            print(fus.shape)\n        \n        y_pr = model(x,fus)\n        y_pr = F.softmax(y_pr,dim=1)\n        print(y_pr)\n        y_pr = torch.argmax(y_pr,dim=1).cpu()\n        \n        if(i==0):\n            print(y_pr)\n            \n        for j in range(len(x)):\n            l = [idx[j],y_pr[j].item()]\n            pred.append(l)\n            \ndf = pd.DataFrame(pred, columns = ['unique_id', 'citation_class_label']) \ndf.set_index('unique_id', inplace = True)\n\nprint(df)\ndf.to_csv('./submission4.csv') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['citation_class_label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['citation_class_label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tx[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Modelfusion(1).cuda()\nm = model(tx[0].cuda().view(1,-1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ysec[0].float()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ysec[0].float().cuda().view(1,1,-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"att.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.cat((att.view(5,20,-1),ysec[0].float().cuda().view(1,1,-1)), 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(att[0][0][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"att.view(5,20,-1).shape","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}